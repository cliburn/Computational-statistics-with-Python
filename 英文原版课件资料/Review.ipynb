{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical foundations\n",
    "\n",
    "- Experimental design\n",
    "    - Usualy want to isolate a main effect from confounders\n",
    "    - Can we use a randomized experiment design?\n",
    "        - Batch effects\n",
    "- Replication\n",
    "    - Essential for science\n",
    "- Exploratory data analysis\n",
    "    - Always eyeball the data\n",
    "    - Facility with graphics librareis is essential\n",
    "    - Even better are interactive graphics libraries (IPython notebook is ideal)\n",
    "        - Bokeh\n",
    "- As amount of data grows\n",
    "    - Simple algorithms may perform better than complex ones\n",
    "    - Non-parametric models may perform better than parametric ones\n",
    "    - But big data can often be interpreted as many pieces of small data\n",
    "\n",
    "## Computing foundations\n",
    "\n",
    "- Polyglot programming\n",
    "    - R and/or SAS (for statistical libraries)\n",
    "    - Python (for glue and data munging)\n",
    "\t- C/C++ (for high performance)\n",
    "    - Command line tools and [Unix philosophy](http://www.faqs.org/docs/artu/ch01s06.html)\n",
    "    - SQL (for managing data)\n",
    "\t- Scala (for Spark)\n",
    "- Need for concurrency\n",
    "    - Functional style is increasingly important\n",
    "        - Prefer immutable data structures\n",
    "\t    - Prefer pure functions\n",
    "            - Same input always gives same output\n",
    "\t        - Does not cause any side effects\n",
    "- With big data, lazy evaluation can be helpful\n",
    "    - Prefer generators to lists\n",
    "    - Look at the `itertools` standaard library in Python 2\n",
    "- Composability for maintainability and extensibility\n",
    "    - Small pieces, loosely joined\n",
    "    - Combinator pattern\n",
    "\t- Again, all this was in the original [Unix philosophy](http://www.faqs.org/docs/artu/ch01s06.html)\n",
    "\n",
    "## Mathematical foundations\n",
    "\n",
    "- Core: probability and linear algebra\n",
    "- Calculus is important but secondary\n",
    "- Graphs and networks increasingly relevant\n",
    "\n",
    "## Statistical algorithms\n",
    "\n",
    "- Numbers as leaky abstractions\n",
    "- Don't just use black boxes\n",
    "    - Make an effort to understand what each algorithm you call is doing\n",
    "    - At minimum, can you explain what the algorithm is doing in plain English?\n",
    "    - Can you implement a simple version from the ground up?\n",
    "- Categories of algorithms\n",
    "    - Big matrix manipulations (matrix decomposition is key)\n",
    "    - Continuous optimization - order 0, 1, 2\n",
    "\t    - Most convenient = [scipy.optimize](http://docs.scipy.org/doc/scipy/reference/optimize.html#module-scipy.optimize)\n",
    "\t    - For convex optimization [cvxpy](http://www.cvxpy.org/en/latest/)\n",
    "\t- EM algorithm has wide applicability in both frequentist and Bayesian domains\n",
    "\t- Graph algorithms\n",
    "\t    - Most convenient = [networkx](http://networkx.github.io/)\n",
    "\t    - Fastest on single and multi-core machines = [graph-tool](https://graph-tool.skewed.de/)\n",
    "\t\t- For cluster = [Spark GraphX](https://spark.apache.org/graphx/))\n",
    "\t- Monte Carlo methods, MCMC and simulations\n",
    "- [Machine learning](https://www.cbinsights.com/blog/python-tools-machine-learning/)\n",
    "    - \t[sklearn](http://scikit-learn.org/stable/)\n",
    "    - MADLib in [SQL](https://github.com/madlib/madlib) or [Python](https://github.com/pivotalsoftware/pymadlib)\n",
    "    - [Spark MLLib](https://spark.apache.org/mllib/)\n",
    "- Making code fast\n",
    "    - Make it run, make it right, make it fast\n",
    "    - Python has amazing profiling tools - use them\n",
    "\t- For profiling C code, try [gperftools](https://code.google.com/p/gperftools/)\n",
    "\t- Compilation: Try numba or Cython in preference to writing raw C/C++\n",
    "\t- Parallel programming\n",
    "\t    - Python GIL\n",
    "\t    - Use Queue from threading or multiprocessing to build a pipeline\n",
    "\t\t- Skip OpenMP (except within Cython) and MPI\n",
    "- Big data\n",
    "    - [Spark](http://spark.apache.org/) is the killer app\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buidling a parallel pipelline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Queue, Process\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Worker(Process):\n",
    "    def __init__(self, func, in_queue, out_queue):\n",
    "        super(Worker, self).__init__()\n",
    "        self.func = func \n",
    "        self.in_queue = in_queue\n",
    "        self.out_queue = out_queue\n",
    "        \n",
    "    def run(self):\n",
    "        while True:\n",
    "            try:\n",
    "                item = self.in_queue.get()\n",
    "            except IndexError:\n",
    "                sleep(0.01)\n",
    "            else:\n",
    "                self.out_queue.put(self.func(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f1 = lambda x: x+1\n",
    "f2 = lambda x: x*2\n",
    "f3 = lambda x: x%4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iq1 = Queue(10)\n",
    "oq1 = Queue(10)\n",
    "iq2 = Queue(10)\n",
    "oq2 = Queue(10)\n",
    "iq3 = Queue(10)\n",
    "oq3 = Queue(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-ddb29f2d3bb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0miq1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moq3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cliburn/anaconda/lib/python2.7/multiprocessing/queues.pyc\u001b[0m in \u001b[0;36mput\u001b[0;34m(self, obj, block, timeout)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mFull\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ps = [Worker(f1, iq1, oq1), Worker(f2, iq2, oq2), Worker(f3, iq3, oq3)]\n",
    "for p in ps:\n",
    "    p.start()\n",
    "\n",
    "for i in range(100):\n",
    "    iq1.put(i)\n",
    "    \n",
    "print len(oq3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
