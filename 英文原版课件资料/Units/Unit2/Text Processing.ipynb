{
 "metadata": {
  "name": "",
  "signature": "sha256:889ab9832b53e433ed345dd88a2ee90c8ca1dde905adfe834bd19438f974e8fe"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "%precision 4\n",
      "import os, sys, glob\n",
      "import regex as re\n",
      "import string"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Preprocessing textual data\n",
      "====\n",
      "\n",
      "Common applciations where there is a need to process text include:\n",
      "\n",
      "1. Where the data *is* text - for example, if you are performing statistical analysis on the content of a billion web pages (perhaps you work for Google), or your research is in statistical natural language processing.\n",
      "2. Where you have to preprocess messy real world dataa - e.g. column titles that are inconsistent in order to construct a DataFrame for analysis.\n",
      "\n",
      "You may need to refer to the following:\n",
      "\n",
      "* For string constatns and some utilitiels, see the `string` module - e.g `string.punctuation`, `string.ascii_lowercase()`\n",
      "* For basic text processing, see string methods - e.g. `lower()`, `upper()`, `split()`, `replace()`, `find()`, `count()`\n",
      "* For regulear expression use, see the `re` module functions, especially `compile()`, `match()`, `search()`, `sub()`\n",
      "\n",
      "As usual, make liberal use of IPython help (e.g `string.punctuation?`) to get information on a specific function or classs.\n",
      "\n",
      "We will illustrate the use of string methods, regular expressions and natural langauge parsing, as well as some Python built-in data structures (e.g. Multiset (counter) and set) that can be used to clean or analyze text data. This is meant only as an walk-thourgh of some of the tools available; refer to the documentation for detals:\n",
      "\n",
      "* [The string module](https://docs.python.org/2/library/string.html>)\n",
      "* [String methods](https://docs.python.org/2/library/stdtypes.html#string-methods)\n",
      "* [The re module](https://docs.python.org/2/library/re.html)\n",
      "* [The regex module - new version of regular expression module](https://pypi.python.org/pypi/regex)\n",
      "* [Tutorial on regular expression](http://www.diveintopython.net/regular_expressions/)\n",
      "* [NLTK](http://www.nltk.org/)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Example: Counting words in a document\n",
      "\n",
      "Perhaps the most basic thing we can do with textual data is to first tokenize (spilt into words) the document, then count the number of times each word (or pair of words, or ...) occurs. We will use the book (How to be Happy Though Married) as an example (from Project Gutenberg)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests\n",
      "url = \"http://www.gutenberg.org/cache/epub/35534/pg35534.txt\"\n",
      "raw = requests.get(url).text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# peek at the first 1000 characters of the downloaded text\n",
      "raw[:1000]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "u'\\ufeffProject Gutenberg\\'s How to be Happy Though Married, by Edward John  Hardy\\r\\n\\r\\nThis eBook is for the use of anyone anywhere at no cost and with\\r\\nalmost no restrictions whatsoever.  You may copy it, give it away or\\r\\nre-use it under the terms of the Project Gutenberg License included\\r\\nwith this eBook or online at www.gutenberg.org\\r\\n\\r\\n\\r\\nTitle: How to be Happy Though Married\\r\\n       Being a Handbook to Marriage\\r\\n\\r\\nAuthor: Edward John  Hardy\\r\\n\\r\\nRelease Date: March 9, 2011 [EBook #35534]\\r\\n\\r\\nLanguage: English\\r\\n\\r\\n\\r\\n*** START OF THIS PROJECT GUTENBERG EBOOK HOW TO BE HAPPY THOUGH MARRIED ***\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nProduced by Colin Bell, Christine P. Travers and the Online\\r\\nDistributed Proofreading Team at http://www.pgdp.net (This\\r\\nfile was produced from images generously made available\\r\\nby The Internet Archive)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n[Transcriber\\'s note: The author\\'s spelling has been maintained.\\r\\n\\r\\n+ signs around words indicate the use of a different font in the book.\\r\\n\\r\\nIn the word \"Puranic\", the \"a\" is overlined i'"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Getting real cnntent\n",
      "The actual content of Project Guternberg books are delimited by the phrases `\"*** START OF THIS PROJECT GUTENBERG EBOOK THE KING JAMES BIBLE ***` and `End of the Project Gutenberg EBook` respectively. Since the actual book title will vary from book to book, we will use a regular expression to search for `*** START OF THIS PROJECT GUTENBERG EBOOK <STUFF> ***`. For the end of the book, we can use a simple string search, but will use a regular expression too for consistency. Note that we need the index of the last character and the index of the first character respectively as limits to extract only the text of the downloaded book."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = re.search(r\"\\*\\*\\* START OF THIS PROJECT GUTENBERG EBOOK .* \\*\\*\\*\", raw).end()\n",
      "stop = re.search(r\"End of the Project Gutenberg EBook\", raw).start()\n",
      "text = raw[start:stop]\n",
      "text[:1000]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "u'\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nProduced by Colin Bell, Christine P. Travers and the Online\\r\\nDistributed Proofreading Team at http://www.pgdp.net (This\\r\\nfile was produced from images generously made available\\r\\nby The Internet Archive)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n[Transcriber\\'s note: The author\\'s spelling has been maintained.\\r\\n\\r\\n+ signs around words indicate the use of a different font in the book.\\r\\n\\r\\nIn the word \"Puranic\", the \"a\" is overlined in the book.]\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n_HOW TO BE HAPPY THOUGH MARRIED._\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nPRESS NOTICES ON THE FIRST EDITION.\\r\\n\\r\\n  \"_If wholesome advice you can brook,\\r\\n    When single too long you have tarried;\\r\\n  If comfort you\\'d gain from a book,\\r\\n    When very much wedded and harried;\\r\\n  No doubt you should speedily look,\\r\\n    In \\'How to be Happy though Married!\\'_\"--PUNCH.\\r\\n\\r\\n\\r\\n\"We strongly recommend this book as one of the best of wedding presents.\\r\\nIt is a complete handbook to an earthly Paradise, and its author may be\\r\\nregarded as the Murray of Matrimony and the Baedeker of Bliss.\"--_Pall\\r\\nMall Gaze'"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Splitting into words - version using standard string methods"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# A naive but workable approach would be to first strip all punctuation, \n",
      "# convert to lower case, then split on white space\n",
      "words1 = re.sub(ur\"\\p{P}+\", \"\", text.lower()).split()\n",
      "print words1[:100]\n",
      "len(words1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'produced', u'by', u'colin', u'bell', u'christine', u'p', u'travers', u'and', u'the', u'online', u'distributed', u'proofreading', u'team', u'at', u'httpwwwpgdpnet', u'this', u'file', u'was', u'produced', u'from', u'images', u'generously', u'made', u'available', u'by', u'the', u'internet', u'archive', u'transcribers', u'note', u'the', u'authors', u'spelling', u'has', u'been', u'maintained', u'+', u'signs', u'around', u'words', u'indicate', u'the', u'use', u'of', u'a', u'different', u'font', u'in', u'the', u'book', u'in', u'the', u'word', u'puranic', u'the', u'a', u'is', u'overlined', u'in', u'the', u'book', u'how', u'to', u'be', u'happy', u'though', u'married', u'press', u'notices', u'on', u'the', u'first', u'edition', u'if', u'wholesome', u'advice', u'you', u'can', u'brook', u'when', u'single', u'too', u'long', u'you', u'have', u'tarried', u'if', u'comfort', u'youd', u'gain', u'from', u'a', u'book', u'when', u'very', u'much', u'wedded', u'and', u'harried', u'no']\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "86545"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Splitting into words - version using the NLTK (Natural Langauge Tool Kit)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# If you need to be more careful, use the nltk tokenizer.\n",
      "import nltk\n",
      "from multiprocessing import Pool\n",
      "from itertools import chain\n",
      "punkt = nltk.data.load('tokenizers/punkt/english.pickle')\n",
      "sentences = punkt.tokenize(text.lower())\n",
      "# since the tokenizer works on a per sentence level, we can parallelize\n",
      "p = Pool()\n",
      "words2 = list(chain.from_iterable(p.map(nltk.tokenize.word_tokenize, sentences)))\n",
      "p.close()\n",
      "# Now remove words that consist of only punctuation characters\n",
      "words2 = [word for word in words2 if not all(char in string.punctuation for char in word)]\n",
      "# Remove contractions - wods that begin with '\n",
      "words2 = [word for word in words2 if not (word.startswith(\"'\") and len(word) <=2)]\n",
      "print words2[:100]\n",
      "len(words2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'produced', u'by', u'colin', u'bell', u'christine', u'p.', u'travers', u'and', u'the', u'online', u'distributed', u'proofreading', u'team', u'at', u'http', u'//www.pgdp.net', u'this', u'file', u'was', u'produced', u'from', u'images', u'generously', u'made', u'available', u'by', u'the', u'internet', u'archive', u'transcriber', u'note', u'the', u'author', u'spelling', u'has', u'been', u'maintained', u'signs', u'around', u'words', u'indicate', u'the', u'use', u'of', u'a', u'different', u'font', u'in', u'the', u'book', u'in', u'the', u'word', u'puranic', u'the', u'a', u'is', u'overlined', u'in', u'the', u'book', u'_how', u'to', u'be', u'happy', u'though', u'married._', u'press', u'notices', u'on', u'the', u'first', u'edition', u'_if', u'wholesome', u'advice', u'you', u'can', u'brook', u'when', u'single', u'too', u'long', u'you', u'have', u'tarried', u'if', u'comfort', u'you', u'gain', u'from', u'a', u'book', u'when', u'very', u'much', u'wedded', u'and', u'harried', u'no']\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "87158"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Counting words"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "c = Counter(words2)\n",
      "c.most_common(n=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "[(u'the', 4356),\n",
        " (u'of', 3322),\n",
        " (u'and', 2699),\n",
        " (u'to', 2601),\n",
        " (u'a', 2335),\n",
        " (u'in', 1524),\n",
        " (u'is', 1209),\n",
        " (u'that', 1059),\n",
        " (u'it', 848),\n",
        " (u'be', 819)]"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Ignoring stopwords"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this isn't very helpful since there are many \"stop\" words that don't man much\n",
      "# now just the top 10 wordss give a good idea of what the book is about!\n",
      "stopwords = nltk.corpus.stopwords.words('english')\n",
      "new_c = c.copy()\n",
      "for key in c:\n",
      "    if key in stopwords:\n",
      "        del new_c[key]\n",
      "new_c.most_common(n=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "[(u'wife', 353),\n",
        " (u'one', 352),\n",
        " (u'life', 271),\n",
        " (u'man', 241),\n",
        " (u'would', 237),\n",
        " (u'said', 227),\n",
        " (u'may', 219),\n",
        " (u'husband', 208),\n",
        " (u'good', 205),\n",
        " (u'children', 194)]"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### What is the difference between words1 and words2?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# words in words1 but not in words2\n",
      "w12 = list(set(words1) - set(words2))\n",
      "w12[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "[u'wedmore',\n",
        " u'servantgirl',\n",
        " u'childs',\n",
        " u'folklore',\n",
        " u'mores',\n",
        " u'loveletters',\n",
        " u'itliterary',\n",
        " u'motheror',\n",
        " u'modium',\n",
        " u'worldthen']"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# words in word2 but not in word1\n",
      "w21 = list(set(words2) - set(words1))\n",
      "w21[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "[u'_john',\n",
        " u\"daughter's\",\n",
        " u'_illustrated',\n",
        " u'party.',\n",
        " u'seventy-seven',\n",
        " u'34.',\n",
        " u'co-operation',\n",
        " u'mercury._',\n",
        " u'proudie',\n",
        " u'_publishers']"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext version_information\n",
      "\n",
      "%version_information requests, regex, nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The version_information extension is already loaded. To reload it, use:\n",
        "  %reload_ext version_information\n"
       ]
      },
      {
       "html": [
        "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>2.7.5 (default, Mar  9 2014, 22:15:05) [GCC 4.2.1 Compatible Apple LLVM 5.0 (clang-500.0.68)]</td></tr><tr><td>IPython</td><td>2.1.0</td></tr><tr><td>OS</td><td>posix [darwin]</td></tr><tr><td>requests</td><td>2.3.0</td></tr><tr><td>regex</td><td>2.4.46</td></tr><tr><td>nltk</td><td>2.0.4</td></tr><tr><td colspan='2'>Sat Aug 02 13:20:24 2014 EDT</td></tr></table>"
       ],
       "json": [
        "{\"Software versions\": [{\"version\": \"2.7.5 (default, Mar  9 2014, 22:15:05) [GCC 4.2.1 Compatible Apple LLVM 5.0 (clang-500.0.68)]\", \"module\": \"Python\"}, {\"version\": \"2.1.0\", \"module\": \"IPython\"}, {\"version\": \"posix [darwin]\", \"module\": \"OS\"}, {\"version\": \"2.3.0\", \"module\": \"requests\"}, {\"version\": \"2.4.46\", \"module\": \"regex\"}, {\"version\": \"2.0.4\", \"module\": \"nltk\"}]}"
       ],
       "latex": [
        "\\begin{tabular}{|l|l|}\\hline\n",
        "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
        "Python & 2.7.5 (default, Mar  9 2014, 22:15:05) [GCC 4.2.1 Compatible Apple LLVM 5.0 (clang-500.0.68)] \\\\ \\hline\n",
        "IPython & 2.1.0 \\\\ \\hline\n",
        "OS & posix [darwin] \\\\ \\hline\n",
        "requests & 2.3.0 \\\\ \\hline\n",
        "regex & 2.4.46 \\\\ \\hline\n",
        "nltk & 2.0.4 \\\\ \\hline\n",
        "\\hline \\multicolumn{2}{|l|}{Sat Aug 02 13:20:24 2014 EDT} \\\\ \\hline\n",
        "\\end{tabular}\n"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "Software versions\n",
        "Python 2.7.5 (default, Mar  9 2014, 22:15:05) [GCC 4.2.1 Compatible Apple LLVM 5.0 (clang-500.0.68)]\n",
        "IPython 2.1.0\n",
        "OS posix [darwin]\n",
        "requests 2.3.0\n",
        "regex 2.4.46\n",
        "nltk 2.0.4\n",
        "<tr><td colspan='2'>Sat Aug 02 13:20:24 2014 EDT</td></tr>"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}