{
 "metadata": {
  "name": "",
  "signature": "sha256:c189eafcd72a82b18b39a488ab3281f08f638d55e75003461585b3bdcdcd8ae8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Instructions\n",
      "----\n",
      "\n",
      "This is a \"closed book\" examination - in particular, you are not to use any resources outside of this notebook (except possibly pen and paper). You may consult help from within the notebook using ? but not any online references. Violation of any of these exam rules is a violation of the University's honor code and will result in penalty under that code.\n",
      "\n",
      "\n",
      "You have 1 hour and 45 minutes to complete the exam.\n",
      "\n",
      "- <font color=red>Use a new cell for different parts of a question</font>\n",
      "- <font color=red>The maximum score for the mid-terms is 60</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "import glob\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import scipy.linalg as la\n",
      "%matplotlib inline\n",
      "plt.style.use('ggplot')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rpy2.ipython"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Question 1 (10 points)**. \n",
      "\n",
      "Given the 2 matrices\n",
      "```\n",
      "A = np.array([[1,2,3],[4,5,6]])\n",
      "B = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
      "```\n",
      "\n",
      "Perform matrix multiplication of `A` and `B` using the following methods:\n",
      "\n",
      "1. Using nested `for` loops without the `dot` function (4 points)\n",
      "2. Using numpy (2 points)\n",
      "3. Using R (start the first line of a new cell with %%R). You should pass in the A and B matrices defined in Python for full marks, but partial credit will be given if you redefine them in R (4 points)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A1 = np.array([[1,2,3],[4,5,6]])\n",
      "B1 = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = np.zeros((2,4))\n",
      "for j in range(4):\n",
      "    for i in range(2):\n",
      "        tot = 0\n",
      "        for k in range(3):\n",
      "            tot += A1[i,k] * B1[k,j]\n",
      "        result[i,j] = tot\n",
      "\n",
      "print result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 38.000  44.000  50.000  56.000]\n",
        " [ 83.000  98.000  113.000  128.000]]\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.dot(A1,B1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "array([[ 38,  44,  50,  56],\n",
        "       [ 83,  98, 113, 128]])"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "A1_R = matrix(1:6, nrow=2, byrow=TRUE)\n",
      "B1_R = matrix(1:12,nrow=3, byrow=TRUE)\n",
      "\n",
      "A1_R %*% B1_R"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "     [,1] [,2] [,3] [,4]\n",
        "[1,]   38   44   50   56\n",
        "[2,]   83   98  113  128\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font color=blue>Grade (+/- comments)</font>\n",
      "\n",
      "\\-1 for not passing values in."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Question 2 (10 points)**. \n",
      "\n",
      "1. Read the `iris.csv` data set into a Pandas DataFrame. Dispaly the first 4 lines of the DataFrame. (2 points)\n",
      "2. Create a new DataFrame showing the mean `SepalLength`, `SepalWidth`, `PetalLength` and `PetalWidth` for the 3 different types of irises. (4 points)\n",
      "3. Make a scatter plot of `SepalLength` against `PetalLength` where each species is assigned a different color. (4 points)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! head -n6 iris.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "SepalLength,SepalWidth,PetalLength,PetalWidth,Name\r\n",
        "5.1,3.5,1.4,0.2,Iris-setosa\r\n",
        "4.9,3.0,1.4,0.2,Iris-setosa\r\n",
        "4.7,3.2,1.3,0.2,Iris-setosa\r\n",
        "4.6,3.1,1.5,0.2,Iris-setosa\r\n",
        "5.0,3.6,1.4,0.2,Iris-setosa\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris_data = pd.read_csv('iris.csv')\n",
      "print iris_data.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   SepalLength  SepalWidth  PetalLength  PetalWidth         Name\n",
        "0          5.1         3.5          1.4         0.2  Iris-setosa\n",
        "1          4.9         3.0          1.4         0.2  Iris-setosa\n",
        "2          4.7         3.2          1.3         0.2  Iris-setosa\n",
        "3          4.6         3.1          1.5         0.2  Iris-setosa\n",
        "4          5.0         3.6          1.4         0.2  Iris-setosa\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font color=blue>Grade (+/- comments)</font>\n",
      "\n",
      "\\-1 for displaying more than 4 rows"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris_data.groupby('Name').mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>SepalLength</th>\n",
        "      <th>SepalWidth</th>\n",
        "      <th>PetalLength</th>\n",
        "      <th>PetalWidth</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Name</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Iris-setosa</th>\n",
        "      <td> 5.006</td>\n",
        "      <td> 3.418</td>\n",
        "      <td> 1.464</td>\n",
        "      <td> 0.244</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Iris-versicolor</th>\n",
        "      <td> 5.936</td>\n",
        "      <td> 2.770</td>\n",
        "      <td> 4.260</td>\n",
        "      <td> 1.326</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Iris-virginica</th>\n",
        "      <td> 6.588</td>\n",
        "      <td> 2.974</td>\n",
        "      <td> 5.552</td>\n",
        "      <td> 2.026</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "                 SepalLength  SepalWidth  PetalLength  PetalWidth\n",
        "Name                                                             \n",
        "Iris-setosa            5.006       3.418        1.464       0.244\n",
        "Iris-versicolor        5.936       2.770        4.260       1.326\n",
        "Iris-virginica         6.588       2.974        5.552       2.026"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#bool1 = iris_data[:,'Name'=='Iris-setosa']\n",
      "#data1 = iris_data.iloc[:,'Name'=='Iris-setosa']\n",
      "#data1 = iris_data.groupby('Name')\n",
      "\n",
      "# I know this isn't right, but I can't remember how to slice pandas dataframes without\n",
      "# looking it up.\n",
      "\n",
      "plt.scatter(iris_data.iloc[:,0],iris_data.iloc[:,2])\n",
      "plt.xlabel('Sepal Length')\n",
      "plt.ylabel('Petal Length')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "<matplotlib.text.Text at 0x11171f390>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEWCAYAAACEz/viAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xt4U/X9B/D3SSGlbVJq2h+tbR8EhgyIQlHEWwVhxcfL\nBohaptMpTleh7ik6RlG3ecFbZQIVqnaTi7h5qVMRQedTr21xTqkgGEVEkWlrgRKB3ts05/dH1kBo\nkvPN5VzSvl/P42ObnHO+n5yGfHI+38uRZFmWQURE/ZpJ7wCIiEh/TAZERMRkQERETAZERAQmAyIi\nApMBEREBGKBVQ6+88gqqq6shSRKGDh2K+fPnY+DAgVo1T0REQWhyZXDgwAG8/fbbKCkpwaOPPgq3\n240tW7YE3cfhcGgRWsiMGBdjEsOYxBkxLsYkJtyYNEkGiYmJiIuLQ0dHB7q7u9HR0QGbzRZ0HyOe\nZMCYcTEmMYxJnBHjYkxiwo1JkzKRxWLBL37xC8yfPx9msxnjx4/HuHHjtGiaiIgEaHJl0NDQgM2b\nN6OsrAzl5eVob29HdXW1Fk0TEZEASYu1iT744APs2LEDt9xyCwCgqqoKu3fvxk033eTdxuFw+Fze\n5Ofnqx0WEVGfVFFR4f3ZbrfDbrcr7qNJmSgzMxMvvfQSOjs7MXDgQOzYsQMjR4702cZfwPX19VqE\nFxKr1Yqmpia9w/DBmMQwJnFGjIsxicnMzAzry7QmyWDYsGGYPHkyFi9eDEmSMHz4cOTl5WnRNBER\nCdBsnsHMmTMxc+ZMrZojIqIQcAYyERExGRAREZMBERGByYCIiMBkQEREYDIgIiIwGRAREZgMiIgI\nTAZERAQmAyIiApMBERGByYCIiMBkQEREYDIgIiIwGRAREZgMiIgITAZERAQmAyIiApMBERFBw3sg\n19fXY8WKFd7f9+/fjzlz5uDSSy/VKgQiIgpAs2SQmZmJRx55BADgdrtxyy23YNKkSVo1T0REQehS\nJtq5cyfS09ORlpamR/NERHQCXZLBli1bkJubq0fTRETkh+bJwOVyoba2Fueee67WTRNRP+R0muF0\nmvUOw/A06zPosW3bNowYMQLJyck+jzscDjgcDu/v+fn5sFqtWoenyGw2Gy4uxiSGMYkzYlyhxiTL\nMqqrJdx0UxIA4KmnWnDBBTIkSdItJq1UVFR4f7bb7bDb7Yr7SLIsy2oGdaIVK1YgJycHF154oeK2\n9fX16gcUIqvViqamJr3D8MGYxDAmcUaMK9SYnE4zpk+3oaHBUwDJyHCjstIJm61Tt5i0kJmZGdZ+\nmpaJ2tvbsXPnTpx99tlaNktERAo0TQaDBg3C6tWrkZCQoGWzRNQP2WydKC9vQkaGGxkZbpSXN0X1\nqqCv0bzPgIhIKxMntqCysgsAmAgUMBkQUZ/W1handwgxgWsTEVGfVVNjxYwZgzFjxmDU1Bhv1I+R\nMBkQUZ9UV5eAoqIkNDSY0NBgQlFREurq2F8ZCJMBEcU0TiqLDiYDIopZW7cmYfp0G6ZPt2Hr1iSf\n57Ky2lBa2uIdTVRa2oKsrDadIjU+diATUUxyOs0oKLB6J5UVFFhRWdnlM2ooN7cJGze6AICJQAGT\nARH1aUwCYlgmIqKYxEll0cUrAyKKWWpPKuvpmO4PSYZXBkQU02y2TlU+rIN1TvdFTAZERCc4vnO6\nocGEggJrnx++ymRARJrgfABjYzIgItXFWsmlP3ZOswOZiFQlMh/AiPrbiqdMBkREAfSHJNCDZSIi\nUlV/LLnEIl4ZEJHq+lvJJRYxGRBR1ASbpBUsCag5uas/TRyLhGZlopaWFjz66KO47bbbcNttt2H3\n7t1aNU1EGgh3xJCaI41ibRSTnjS7Mli7di0mTJiA3//+9+ju7kZHR4dWTROpit88PeeguDgJP/+5\n5xwUFyfhxReVRwypOdIoVkcx6UWTK4PW1lbs2rUL06ZNAwDExcUhMTFRi6aJVMVvnh4mE1BQ0IFN\nm8zYtMmMgoIOmDg8JaZo8uc6cOAAkpOT8fjjj6O4uBhPPvkkrwwo5vXHJQsCcbuBkpIE77koKUmA\n2628n5ojjTiKKTSalIm6u7uxd+9e3HjjjRg5ciTWrVuHDRs2YM6cOd5tHA4HHA6H9/f8/HxYrca7\ngbXZbDZcXIxJTLRjam6WA7QRr1tMACDLMhoaPD9nZACSJIV8DH9xBTtuJOfiwgtlvP9+8/+OK0GS\n/J+PcM6V6LHDZcT3OQBUVFR4f7bb7bDb7Yr7aJIMUlNTYbPZMHLkSADAOeecgw0bNvhs4y/gpqYm\nLcILidVqNVxcjElMtGOyWIDychkFBZ4Pg/LyJlgsLQilCTXO09atST4xTZzYHPIx/MUV7LiRnguL\nxfP/5iChhnuuRI4dLqO+z/Pz80PeT5NkkJKSgrS0NNTX1yMzMxM7duxAdna2Fk0Tqcpo4+fV6jQV\nOa7RzgWFRrPRRHPnzsXKlSvhcrmQnp6O+fPna9U0karC/eBzOs1obpa931xD3TeStolOpFkyGDZs\nGB566CGtmiMyNN+Si4yJE1vC3LfJZ9+eTtPjn49GwhA5brC4yPgkWZZ79/wYRH19vd4h9GLUGiFj\nUmaUmJxOM6ZPt3lLLhkZblRWOoU+tEX3jfTKIdC5CnTcSF5TpDHpyYgxZWZmhrUfl6MgijGnnOLC\nH//o+ZB95hn/Q1nVWvqBZam+i9NCiDQWyfh3m60TCxZ04P77E3H//YlYsKAjpA9otSbJcUx/7GOZ\nKERGvCxkTGKMFpPTaYbZbIbFIj7msa4uATNmDPYpx2zceARZWW1C7YmWcsI9V2p2bBvt7wcYMyaW\niYgiEMmHWF1dAgD4/UAO9pzN1gmrNT6keQlGx6uB2MUyEfV7kZROamqsmDFjMGbMGIyaGqvwc+HK\nymrD8uUt3nLM8uUtQlcFAEs5FBzLRCEy4mUhYxLjL6ZIRsEEK9nU1SXg17+2IjfXBQCoqRmA9eub\nfD64wykTOZ1mXHVVis9xX3zxcEijiUSugmLl76c3I8bEMhGRgfSs4llS4ikTFRe3+aziGck8g8OH\nTXjqqUEAPAnoRErj/Xk1QP6wTET9WiSlk6ysNpSWHivZlJYeK9nEx3f3WsUzPr4bQGSrnSrFy5VU\nKVy8MqB+T2lNnWBlldzcJmzc6CnZiNbuIxXpGkBcyoL84ZUBETwfjP4+HEU6l7Oy2nolgmDf4KPR\nkRsoXqVj82Y8FAg7kENkxA4jxiQm1JiiscSCUkduqB3IkbSrxTwDNTEmMexAJjKgtra4gM+pOc+A\nJSAKFctERAFEWs5RY55BJDjPgILhlQFREOF21tbVJaCoKMlbkikqSsLGjS7NOpkD4Q1oKJCQk4H7\nhLtcm0y8uKC+Ta0PTb1ubsMkQP4IJYNvvvkGq1evxr59+9DV1eXz3AsvvKBKYESxzDMHYQCKijwj\ndo6fgwCod3MbonAJjSb6/e9/jzPPPBOTJ0+G2ew7gWXIkCGqBcfRRGIYkxg9YvK3UJ0WN7eJFP9+\nYowYk6qjiRobG3H11VdDkqSwGiGKhn37EgEAp5zS6vd5pWGc4ZZklARrV+8+An846Yz8ESr4n3XW\nWfj0008jbqywsBALFy7EokWLcMcdd0R8POo/qqqsmD07GbNnJ6OqqvfInGCTqXqemzLFEvWJVuFM\n4rLZOnstYxHKzW0iGRHESWcUSMAy0cqVK70/u1wubN26FWPGjMHgwYOP7SxJuPXWW4UbKywsRElJ\nCSyCX89YJhLTl2Ly9611375EzJ6d7FMaefnlo94rhGClE9FVPsMR7rGjEVOw+yQEa5eTzqLLiDFF\nvUyUnp4OSZIgyzIkSUJWVpb3ueMfD5WBJzyTztToGFVaPVSvYyutPBqM73kysQOZokKoA/nHH3/E\nSSedJPx4ILfeeisSExNhMpmQl5eHvLy8oNvzykBMX4hJ6VtrVZUVt93mKWssX96CyZN9jx0okajZ\n4RrJscNNfJG+HtF2+8J7SgtGjEnVDuQFCxbg6aef7vX47bffjrVr1wo3tmTJEpx00kk4evQolixZ\ngqysLIwZMwYA4HA44HA4vNvm5+fDatV/1uaJzGaz4eKKpZhkWUZDg+fnjAx4ry6bm3t/J/EcIx4A\ncPHF3Rg2zPOPbvRoGXFxvse+8EIZ77/f/L/jSpAkq9Bxg8WkROTYgfTEGxcXh//7v2PxqtkmAEyZ\n4sbmzZ7z+JOfACaT/3Zj6T2lJyPGBAAVFRXen+12O+x2u+I+QsnA38VDa2tryBPOeq4ikpOTMWnS\nJOzZs8ebDPwFbLSMCxjzm0AsxdT7m6nnA9xi8Yy3P/45i6XFZ92eoUM9/2/1P5jIO1Koudn3MaXj\nBopJicUCLF8u+VyxWCzNwmsNWSw950l8oTqR1xNM79fqf8dYek/pyagx5efnh7xf0DLRvHnzAABO\npxM2m83nuaamJpx//vnebZR0dHTA7XYjISEB7e3teOCBB3DllVdi/PjxAfdhmUhMrMQkUuJQa9hj\noBVCI73tpdKtLZVEs6NdZB92IEeXEWNSpUzUM1LowQcfxO9+9zvvFYIkSRg8eLBPp7KSI0eOYOnS\npQA8S1rk5uYGTQTUP0WSBNRMJIGOG0lHcCRERiyJbEfUQ6gDuaOjA/HxYjXJaOKVgZhYikmtpRSC\nHVepzUj2ramx+iw5kZsb2t9Bjb9dJK9HzbgixZjEhHtlIJQMnn/+eb+dagMGDEBqaipycnKQkpIS\nVgDBMBmIibWYov2tVWmegUhpJJKbwYQz5r9HtP920SrFxdp7Si9GjEnV0UQ//PADPv74Y4wcORKp\nqalobGzE119/jTPOOAO1tbVYvXo1br/9dkyYMCGsIKh/MWLpIthNaJQkJHRHMRIxaq5aqubSHWRc\nQsOBZFnGggULcN9996GoqAhLlizBbbfdBpPJhAcffBC/+c1v8Oyzz6odK5Ffkd5vONBNaET21WN5\nh2BtRmu5CjWW7iBjEyoTXX/99Vi7dq3PUNLu7m7MnTsX69ev9/k5mlgmEsOYPMK537DIiKBAx410\nApjSPZAjKV2pPdpID3yfiwm3TCR0ZZCeno4333zT57HKykpkZGQA8Awz1aODmeh4NltnwA8um60T\nJ5/cu9+rZ0mJTZvM2LTJjIKCjl5LSgQ7briUvoFHesWhRszUtwldGXzzzTf4y1/+ArfbDZvNBqfT\nCZPJhIULF2LEiBH4/PPPUV9fr7i8RKh4ZSCGMYkJd+5DMOGMjlJqU+l5NW9uY+Qb58TKe0pvqnYg\njxgxAo899hh2797tXY9o1KhRGDDAs/vYsWMxduzYsAKg4Iw6XjySuJTKOeEeN5i6ugTExbnxv4vZ\nkASLSemewmq8HjXvY9xzbE/5yjiJgNQnvJ7EgAEDMHbsWJx77rkYPXo0TCZTr/shU3QZde35SOIS\nue9AtF9vTwfxZZdZfTqIAeUOV5GYApVkAu2r1KZIJ7CaZaBAJTXq24TLRHrcA7k/l4mMunSAaFyh\nlmTU6rysq0vAjBmDfY67ceORXnMCIums9Ud0vH+oHchaMWL5gzGJUbVMVFZWhjPPPBPz5s3rdQ9k\nohPF4jh1PZbBsNk6YbXGCy8yF402iQIRKhP13AM5OzsbQ4YM8fmP1BHpeHG94go2SibS+QDhyMpq\n63WLSdGZwpHMM1Dz9pRGLR9SbBMqE61atQq5ubnIycnRIiav/lwm6mHUpQPUGgOvbgeyCRkZoXeK\nRjLPQOn1GKWcJhKX3hiTGFXLRJ2dnVi6dGnE90Cm0BnhasCfSOIKtq9arzcrq+1//3BVOTxRzBMq\nE2VnZ2PmzJkYNWoU0tPTkZGRgfT0dKSnp6sdH8UQo5a2IhHJ0g/hlnP0KKcRCZWJ9MIykRijxaQ0\nSkYv0b4v8/HbAeGVzMJd3VXtDmSjvacAxiRK1TIRAHz66afYsmULjh49isWLF+Prr79GW1sbTjvt\ntLAapr5LaZRMsA+ySJaD1muEjZrj/bVuk/ovoTLRG2+8gaeeegonn3wyvvjiCwDAwIED8fzzz6sa\nHPU9wUongVYPjfS44YqkJMNyDsUaoSuDzZs3489//jOGDBmCjRs3AvD0I9TV1akaHPUtTqcZBQVW\nb+mkoMCKysou2GydqKtLwN13J+DnP/d8YN59dwLWr3cJrx4a6LiRimTpBzWXjSCKNqErg/b2dqSm\npvo85nK5MHDgQFWCov5HafVQPcfWR7L0A1cPpVghlAxGjx6NDRs2+Dz2xhtvwG63h9SY2+3GokWL\n8PDDD4e0H/UNJhNQXNzmLZ0UF7d5P/Dj47tRUpKAhgYTGhpMKClJQHy85w5ix3/zb2gwoaDA6r1K\nAFiSIYoGoTLRjTfeiJKSErz99ttob29HUVERBg0ahMWLF4fU2Ouvv47s7Gy0tYXeOUixI9AKoW43\nUF4e7y0FlZfHIy9P7L2QkuL27ldT0/ttK7J6aLAlMri8A/V3QsnAZrPhoYcewtdff42DBw8iLS0N\nI0eOxMGDB4UbOnToELZt24bLL78cmzZtCjtgMraaGiuKijxlnNJSE3Jzjw0pstk6UVLS4rNe/onj\n5wM9d++9bccdt8Xvh3agD3LfNfrlXmv0G3kNfyKthD3PoLOzE9ddd53wqqXLli3D5Zdfjra2Nmzc\nuFHoqoLzDMQYJaZIVggN9pyaq4fqfatHo/ztTmTEuBiTGNXnGUSitrYWycnJGD58OBwOh99tHA6H\nz3P5+fmwWkMbXqgFs9lsuLjCiUmWZTQ0eH7OyPAsLRKpuLje97eIizP5xCbLMpr/NxfNYjH3avfY\npsduo9rc3Pv7iuc1K99qVWnfSI4dDUZ8PwHGjIsxiauoqPD+bLfbhfp3NbkyePbZZ1FdXQ2TyYSu\nri60tbXh7LPPVlzXiFcGYsKJSa3SiG+ZqMWnTBRJu0rHDUapTT3LREZ8PwHGjIsxiQn3yiDsZNDV\n1YVrr7025JvbfP755ywTRZlayyyEK9AKoeG263SacdVVKcjNdQHwdCC/+OLhkOI16o1kjPh+AowZ\nF2MSo0qZaN68eWEdVEk0ShJkXAkJ3TCb46J6zMOHTXjqqUEAPEkkVEpLZHAUEfV3QZOBUhknnA/1\nsWPHYuzYsSHvR9ETbOROpIKN3Am3XTXjJSIPrloaIiNeFoYbU7RLI9G4uY3S8cPZr0df+tupzYhx\nMSYxhh5NRMakxrdrpclhkbTLqwEi9TAZUNSITg4jIuMRWpuISITTaUZRUZJ3DaGioiSfNYSO387f\n40SkHyYD0pSeq48SUWABy0QrV65U3FmSJMURR9R/KI36UfO+A0QUmYDJID09HZIkIdhgI84X0J/S\napxa61k91DPBK/SZvFw9lEgfAZNBfn6+lnFQGJRW49RLoAleSlcOXD2USD/Co4lcLhfq6+tx9OhR\nn8dPO+20qAdFymK15BLovgOx+nqI+gqhZLBr1y4sW7YMXV1daG1tRWJiItra2pCWloZVq1apHSP1\nMfyAJzIeodFE69atw4wZM7B27VokJiZi7dq1uPLKK3HRRRepHR8F0Ndu9djXXg9RrBG6Mvjhhx9w\n6aWXAoC3Q3nWrFkoLCzEjBkz1IuOgoq0s9ZolG5dSUTqEUoGiYmJaG1thcViwUknnYTvvvsOVqsV\n7e3tasfX7/W30TX95XUSGY1QmWjSpEnYtm0bAGDq1Km47777UFxcjHPOOUfV4Po7pQlaPc9PmWLh\nBC4iikhYq5Z+8cUXaGtrQ05ODkwm9SYx9+dVS41+714lRlzNkTGJM2JcjElMuKuWCn2Sr1mzxuf3\nMWPG4IwzzsD69evDapSIiIxFKBm89957fh9///33oxkLHUdpdA1H3xBRNAXtQH7nnXcAAN3d3d6f\ne+zfvx/JycnqRUaKo2v62mgiItJP0GRQVVUFSZLQ3d2N6upqn+cGDx6MwsJCVYMj5dE1Svf2JSIS\nETQZ3HPPPQCA5557DldffXVEDXV2duKee+5BV1cXXC4XzjrrLFxzzTURHZOIiKJDaJ7B1Vdfjaam\nJnzyySc4fPgwZs6cCafTCVmWkZqaKtSQ2WzG3Xffjfj4eHR3d+PPf/4zdu3ahdGjR0f0Aiiw/jZH\ngYjCJ9SB/Pnnn2PBggWoqanBSy+9BMAzK/lvf/tbSI3Fx8cD8Cx653a7YTHKust9EG8iQ0ShELoy\nWLt2LYqKijBu3DjMnTsXAHDqqadiz549ITXmdrtRXFyM/fv346KLLkJ2dnboEZMirgBKRKESSgaN\njY0YN26c744DBsDtdofUmMlkwtKlS9Ha2ooHHngADocDdrsdAOBwOOBwOLzb5ufnw2q1hnR8LZjN\nZsPFdWJMzc295xF6tonXLSYjYEzijBgXYxJXUVHh/dlut3s/Z4MRSgZZWVnYvn07cnJyvI/t3LkT\nQ4cODSNMz1pHEyZMwNdff+0N0l/ARpvZBxhzxuGJMVksnpvdHH+jGIulRdMRR7FwnozAiDEBxoyL\nMYmxWq1h3ZxMKBn8+te/RklJCSZMmIDOzk6Ul5ejtrYWixYtEm7o6NGjiIuLQ1JSEjo7O7Fz505c\neeWVIQdMYrgCKBGFQigZjBo1CkuXLkVVVRWmTp2KtLQ0PPTQQ8IjiQDg8OHDKCsrg9vthizLmDx5\nMk4//fSwAydlTAJEJCpoMmhvb8fLL7+M//73vxgxYgRmzZoFs9kcVkNDhw5FSUlJWPsSEZG6gg4t\nXbNmDWpra5GVlYX//Oc/eOaZZ7SKi4iINBQ0GWzbtg133XUXrrvuOtxxxx345JNPtIqLiIg0FDQZ\ndHR0wGazAQDS0tLQ2tqqSVBERKStoH0Gbrcbn332GQDPvY+7u7u9v/c47bTT1IuOiIg0ETQZDB48\nGE888YT3d6vV6vM7AJSVlakTGRERaSZoMuAHPRFR/6DeDYyJiChmMBkQERGTARERMRkQERGYDIiI\nCEwGREQEJgMiIgKTARERgcmAiIjAZEBERGAyICIiMBkQERGYDIiICAqrlkZTY2MjysrKcOTIEUiS\nhJ/97Ge49NJLtWqeiIiC0CwZDBgwANdffz2GDRuG9vZ2FBcXY9y4ccjOztYqBCIiCkCzMlFKSgqG\nDRsGABg0aBCysrLw448/atU8EREFoUufwYEDB/Dtt9/i1FNP1aN5IiI6gWZloh7t7e1YtmwZbrjh\nBgwaNMj7uMPhgMPh8P6en58Pq9WqdXiKzGZzVOOSZRkNDZ6fMzIASZKiElM0jhuJaJ+naGBM4owY\nF2MSV1FR4f3ZbrfDbrcr7iPJsiyrGdTxXC4XSkpKkJOTg8suu0xx+/r6eg2iCo3VakVTU1PUjrd1\naxIKCjxvpvLyJkyc2BKVmKJx3EhE+zxFA2MSZ8S4GJOYzMzMsPbTrEwkyzKefPJJZGVlCSWC/sDp\nNKOgwIqGBhMaGkwoKLDC6TQb9rhE1HdpVib68ssvUV1djaFDh2LRokUAgGuuuQY5OTlahUBERAFo\nlgxGjx6NF154QavmYoLN1ony8iafco7N1mnY4xJR36V5BzL5mjixBZWVXQAQ1Q/siRNbsHGjGwCQ\nldUWteP2qKtLUOXYPeUsJi8ibXE5CgOw2Tqj/uG3dWsSZswYjBkzBmPr1qSoHrumxuo9dk1N9EZS\nbN2ahOnTbZg+3Rb1mIkoOCaDPkjNDuS6ugQUFSV5j11UlOS9SogEO72J9MUykUaClT8iKbns25cI\nSXJj6FDfx1NS3Pj5zz1t1dTwz0xEwfHKQAPByh+RlFyqqqyYPTsZl19uRVXVsX1ttk7ce28bNm0y\nY9MmM+69ty1qZaisrDaUlrYgI8ONjAw3SktbotJv0NPp3XNcdnoTaUvTSWeh6guTzpxOM6ZPt6Gh\nwZN3MzLcqKx0wmbrRF1dAmbMGOzz3MaNR4Q+XPftS8Ts2ck++7788lGcckpr0DajRelqJtzJOGp2\nIBtxgpARYwKMGRdjEmP4SWd9ndNpVqXGvW9fIvbtS4z6cQHPB3qger9ar4eIjInJIAqClYGClT+U\nSi49ZaDZs5N9ykAAcMoprVi+/Ni+y5e34JRTWr1tnvjcid+0g5WnlEb1cDQRUd/DMlGITrwsFC3J\nhNqBHKwM1HO822+3oqCgAwBQXh6PZcs8iWbfvkTceKMFubkuAJ4O5DVrmr37BitPKb0e0dJWNMtp\n0WLES3ojxgQYMy7GJCbcMhGHmRwn3Hr1Kae48Mc/evZ55hn/pRU1auDffReHf/3L7P35eIcPm/DU\nU55VYTMy3FFvOxin04zmZhkWi6bNElEEWCb6n3BLFDZbJxYs6MD99yfi/vsTsWBBR0gf/IFKLsHK\nQD3t3n33sRFDd999bMSQ0r5ZWW29nu/5Zq80qkeptNVzHqdMsYR8HjmaiEg/LBMhtBLFiZeFkYwI\nUirXBCoDKe1bV5eAu+5K9Nn3gQdavTE5nWZcdVWKTxnpxRcP+7xepaskf6WtaJR6OJrIGIwYF2MS\nwzJRhERKPZGUP8L5kNu5cyCuvDIeQOilHqV9lcpISnEmJHT7fTzSyW68GiDSB8tEECv1BCp/iEzC\nClSCCravSLkmUKlHKaZISzKBXo+ak92ISF0sE0G51CNS/gg0CSuSfXv2B3p/YxYp9ShNDAvnaiXY\n61F7RFCkJSQjXtIbMSbAmHExJjEsE+kskiUZgu0b7INPqdSjFFMsfWvX+zaeRH0dy0RQt6yi1igZ\nkwkoLm7zHre4uA0mDf6awV6PWq+VK5oSqa/flYkiWT3U6TTDbDbDYmmOarvhECkTqSnY64nkPAVq\nKxrlJyNe0hsxJsCYcTEmMSwTCVAqNYiUVazWeITzt4/2h7TN1omSkhbdbm0ZrK1IzlOg4/E2nkTq\n0iwZPP7449i2bRuSk5Px6KOPatWs1/GlBgAoKLCisrIrpj9Uem6Z6fkW3rdr6GrdHpSIPDTrM5g6\ndSruvPNOrZrTnF6rfNpsnTj5ZEnzdvWgxu1BichDs2QwZswYJCXptxKlmssdcLVNIop1/arPQI1S\nQ18sPxFR/2OYZOBwOOBwOLy/5+fnw2qN3lr5PY4dMj6s/c1ms09czc29B2N5tgnv+NGIyQgYkxgj\nxgQYMy7yGlhSAAAMiklEQVTGJK6iosL7s91uh91uV9zHMMnAX8BGG7IF9B5KZrEA5eWyz0gXi6Ul\naiNpwonJCBiTGCPGBBgzLsYkxmq1Ij8/P+T9DJMMYhlHuhBRrNMsGaxYsQJffPEFmpqaMG/ePOTn\n52Pq1KlaNa86JgEiimWaJYMFCxZo1RQREYWIaxMRERGTARERMRkQERGYDIiICEwGREQEJgMiIgKT\nARERgcmAiIjAZEBERGAyICIiMBkQERGYDIiICEwGREQEJgMiIgKTARERgcmAiIjAZEBERGAyICIi\naHjby+3bt2PdunVwu92YNm0aZs2apVXTRESkQJMrA7fbjdWrV+POO+/EsmXLsGXLFnz//fdaNE1E\nRAI0SQZ79uxBRkYGhgwZggEDBuD888/H1q1btWiaiIgEaJIMnE4nUlNTvb/bbDY4nU4tmiYiIgHs\nQCYiIm06kG02Gw4dOuT9/dChQ7DZbD7bOBwOOBwO7+/5+fnIzMzUIryQWa1WvUPohTGJYUzijBgX\nYxJTUVHh/dlut8NutyvvJGvA5XLJt956q7x//365q6tLXrhwofzdd98F3eeFF17QIrSQGTEuxiSG\nMYkzYlyMSUy4MWlyZRAXF4cbb7wRDzzwgHdoaXZ2thZNExGRAM3mGUyYMAETJkzQqjkiIgpB3D33\n3HOP3kEEMmTIEL1D8MuIcTEmMYxJnBHjYkxiwolJkmVZViEWIiKKIRxaSkRETAZERKRhB3Iwbrcb\nixcvhs1mw+LFi3s9v2bNGmzfvh3x8fGYP38+hg8frmtMDocDjzzyCNLT0wEAZ599Nq644grVYyos\nLERCQgJMJhPi4uLw0EMP9dpG63OlFJMe56qlpQVPPvmkd/2refPmYdSoUT7baH2elGLS+jzV19dj\nxYoV3t/379+POXPm4NJLL/XZTuvzJBKXHu+pV155BdXV1ZAkCUOHDsX8+fMxcOBAn220PldKMYV8\nnqI6wDVMr732mlxaWio//PDDvZ6rra2VH3zwQVmWZXn37t3ynXfeqXtMn332md/H1TZ//ny5qakp\n4PN6nCulmPQ4VytXrpTffvttWZY9c1xaWlp8ntfjPCnFpNd7SpZlubu7W7755pvlgwcP+jyu1789\npbi0Plf79++XCwsL5c7OTlmWZXnZsmXyu+++67ON1udKJKZQz5PuZaJDhw5h27ZtmDZtGmQ/fdlb\nt27FlClTAACnnnoqWlpacPjwYV1jAhDwcbUFa1ePc6UUk8jz0dTa2opdu3Zh2rRpADxzXBITE322\n0fo8icQE6Pee2rlzJ9LT05GWlubzuF7vJ6W4AG3PVWJiIuLi4tDR0YHu7m50dHT0WkFB63MlEhMQ\n2nnSvUz09NNP49prr0VbW5vf509c5C41NRVOpxMpKSm6xSRJEnbv3o0//OEPsNlsuO666zSZRCdJ\nEpYsWQKTyYS8vDzk5eX5PK/HuVKKSetzdeDAASQnJ+Pxxx/Hvn37MHz4cMydOxfx8fHebbQ+TyIx\n6fWeAoAtW7YgNze31+N6vJ9E4tL6XFksFvziF7/A/PnzYTabMX78eIwbN85nG63PlUhMoZ4nXa8M\namtrkZycjOHDhwfNYFp+CxCJafjw4XjiiSewdOlSXHzxxVi6dKkmsS1ZsgSPPPII7rzzTrz55pv4\n4osvem2j9bdLpZi0Plfd3d3Yu3cvLrroIpSUlGDQoEHYsGFDr+20PE8iMen1nnK5XKitrcW5557r\n93m9rlaCxaX1uWpoaMDmzZtRVlaG8vJytLe3o7q6utd2Wp4rkZhCPU+6JoMvv/wStbW1KCwsRGlp\nKRwOB1atWuWzjcgid1rHlJCQ4P1WN2HCBLhcLjQ3N6sWU4+TTjoJAJCcnIxJkyZhz549Ps9rfa5E\nYtL6XKWmpsJms2HkyJEAgHPOOQd79+712Ubr8yQSk17vqW3btmHEiBFITk7u9Zwe7yeRuLQ+V998\n8w1++tOfwmq1Ii4uDmeffTa+/PJLn220PlciMYV6nnRNBtdccw2eeOIJlJWVYcGCBbDb7bj11lt9\ntpk4cSKqqqoAALt370ZSUpKql6kiMR0+fNj7LaDnw89isagWEwB0dHR4y1bt7e3YsWMHhg4d6rON\n1udKJCatz1VKSgrS0tJQX18PANixY0evS2Otz5NITHq8pwBPKeb888/3+5zW50k0Lq3PVWZmJr76\n6it0dnZClmVDvKdEYgr1POneZ3A8SZIAAJWVlQCA6dOn44wzzsC2bdvwu9/9DoMGDcK8efN0j+nD\nDz9EZWUlTCYT4uPjUVRUpHocR44c8V7mud1u5ObmYvz48bqeK5GY9DhXc+fOxcqVK+FyuZCeno55\n8+bp/p5SikmP89Te3o6dO3eioKDA+5je50kkLq3P1bBhwzB58mQsXrwYkiRh+PDhyMvL0/VcicQU\n6nnichRERMQZyERExGRARERgMiAiIjAZEBERmAyIiAhMBkREBCYDIr8KCwuxc+dOvcMIKhZipNhh\nqElnRCfatWsX/v73v+P777+HyWRCVlYWbrjhBvzkJz9Rve2eCYcnKisrQ2pqKn75y1+qHoNSm4Fi\nJAoVkwEZVmtrKx5++GH89re/xbnnnouuri7s2rWr101FtCZJEj+Eqc9hMiDD+uGHHyBJEs477zwA\ngNls7rVM7zvvvIPXXnsNhw8fxsiRI1FQUOBd/37OnDm44YYb8Prrr6O1tRVTp07Fr371K0iShIaG\nBpSXl+O///0vAGD8+PG46aab/N5nwJ9AE/dra2vx/PPPo7GxEdnZ2bj55pu96zUVFhbi4osvRlVV\nFQ4ePIicnBwUFhZ6k9urr76K119/HZIk4aqrrsJf//pXlJaW4rPPPkNNTQ0kScLrr7+O0047DYsW\nLQIA7N27F08//bTf4xGFgn0GZFiZmZkwmUwoKyvD9u3be624+PHHH2PDhg34wx/+gNWrV2PMmDEo\nLS3ttc3DDz+MkpISfPzxx3j33Xe9z82ePRvl5eVYvnw5Dh06hIqKioji3bt3L5588kkUFBRgzZo1\nyMvLQ0lJCVwul3ebDz/8EHfddRdWrVqFffv24b333gMAbN++HZs3b8af/vQnPPbYY3A4HAA8VyF5\neXm44IILMHPmTKxfv96bCIIdjyhUTAZkWAkJCbjvvvsgSRLKy8tx880345FHHsGRI0cAeBYvmzVr\nljdpzJo1C99++y0aGxu9x5g5cyaSkpKQlpaGyy67DFu2bAEAZGRk4PTTT8eAAQOQnJyMyy67zO/9\nIULx1ltvIS8vDyNHjoQkSZgyZQoGDhyIr776yrvNJZdcgpSUFFgsFpx55pn49ttvAQAffPABpk6d\niuzsbJjNZuTn5/c6vr+rkUDHIwoVy0RkaFlZWZg/fz4Az83SV65ciXXr1qGoqAgHDx7EunXr8Mwz\nz/js43Q6vaWi4+8+lZaWBqfTCcCzvO+6deuwa9cutLW1QZbliJdBbmxsRFVVFf71r395H3O5XPjx\nxx+9vx+/rLHZbPbeGrGnzNXj+LiDOfF4x7dFFAomA4oZmZmZmDJlCt566y0Ang/3K664wu+tEXv0\n1O57fu654chzzz0Hk8mERx99FElJSfjoo4+wdu1a4Vj8dSCnpqbi8ssvx+zZs0N5WQA8H+on3hwl\nVOzUpkiwTESGVV9fj02bNnm/zTc2NmLLli0YNWoUAM+a7a+88gq+//57AJ7RR//+9799jvHaa6+h\npaUFjY2NeOONN7yd0e3t7YiPj0dCQgKcTidee+014bhkWUZ3dzc6Ozu9/7lcLu968nv27IEsy2hv\nb8cnn3yC9vb2oMcCgPPOOw/vvfce6urq0NHRgX/+858+26WkpODAgQOKcRGFi1cGZFiDBg3CV199\nhU2bNqGlpQVJSUk488wzcd111wEAJk2ahPb2dqxYsQIHDx5EYmIixo8f73Pf3LPOOguLFy9Ga2sr\nLrzwQkydOhUAcNVVV2HVqlW44YYbcPLJJ+OCCy7A5s2bheKSJAmvvvoqXn31Ve9jo0ePxr333ouC\nggKsXr0aDQ0NMJvNGD16NMaOHRvwOD3f5nNycnDJJZfg3nvvhclkwuzZs1FdXe0dGTRt2jQsW7YM\nc+fOhd1ux8KFC4MejyhUvLkN9Vlz5szBY489hvT0dL1DCdn333+PhQsX4tlnn4XJxAt4Uh/fZUQG\n8dFHH6GrqwvNzc34xz/+gYkTJzIRkGZYJiIyiLfeeguPP/44TCYTxo4di5tuuknvkKgfYZmIiIhY\nJiIiIiYDIiICkwEREYHJgIiIwGRARERgMiAiIgD/D/gWv4DgRKmYAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10c5a1d10>"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font color=blue>Grade (+/- comments)</font>\n",
      "\n",
      "\\-2 for not coloring by species"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Question 3 (10 points)**.\n",
      "\n",
      "Given the following covariance matrix\n",
      "```python\n",
      "A = np.array([[2,1],[1,4]])\n",
      "```\n",
      "\n",
      "1. Show that the eigenvectors of $A$ are orthogonal. (2 points)\n",
      "2. What is the vector representing the first principal component direction? (2 points)\n",
      "3. Find $A^{-1}$ without performing a matrix inversion. (2 points)\n",
      "4. What are the coordinates of the data points (0, 1) and (1, 1) in the standard basis expressed as coordinates of the principal components? (2 points)\n",
      "5. What is the proportion of variance explained if we keep only the projection onto the first principal component? (2 points)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.linalg as la"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A3 = np.array([[2,1],[1,4]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A3_e, A3_V = la.eig(A3)\n",
      "print 'The result of multiplying the matrix containing the eigenvectors by its transpose is: '\n",
      "print np.dot(A3_V,A3_V.T)\n",
      "print 'Since we obtain the identity matrix, we see that the eigenvectors are orthogonal.'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The result of multiplying the matrix containing the eigenvectors by its transpose is: \n",
        "[[ 1.000 -0.000]\n",
        " [-0.000  1.000]]\n",
        "Since we obtain the identity matrix, we see that the eigenvectors are orthogonal.\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.real_if_close(A3_e)\n",
      "print 'The eigenvector corresponding to the largest eigenvalue is the second eigenvector.'\n",
      "print 'Therefore, the vector representing the first principal component direction is:'\n",
      "print A3_V[:,1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 1.586  4.414]\n",
        "The eigenvector corresponding to the largest eigenvalue is the second eigenvector.\n",
        "Therefore, the vector representing the first principal component direction is:\n",
        "[-0.383 -0.924]\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lam_inv = np.zeros((2,2))\n",
      "lam_inv[0,0] = 1.0 / A3_e[0]\n",
      "lam_inv[1,1] = 1.0 / A3_e[1]\n",
      "\n",
      "A_inv = np.dot(A3_V, np.dot(np.real_if_close(lam_inv),A3_V.T))\n",
      "\n",
      "print 'A inverse is:'\n",
      "print A_inv\n",
      "print \n",
      "print 'A time A**-1 is:'\n",
      "print np.dot(A3,A_inv)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "A inverse is:\n",
        "[[ 0.571 -0.143]\n",
        " [-0.143  0.286]]\n",
        "\n",
        "A time A**-1 is:\n",
        "[[ 1.000  0.000]\n",
        " [ 0.000  1.000]]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:2: ComplexWarning: Casting complex values to real discards the imaginary part\n",
        "-c:3: ComplexWarning: Casting complex values to real discards the imaginary part\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.array([[0,1],[1,1]])\n",
      "\n",
      "X_eig = np.dot(A3_V.T, X)\n",
      "print 'The coordinates of (0,1) in the eigenbasis are:', X_eig[:,0]\n",
      "print 'The coordinates of (1,1) in the eigenbasis are:', X_eig[:,1]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The coordinates of (0,1) in the eigenbasis are: [ 0.383 -0.924]\n",
        "The coordinates of (1,1) in the eigenbasis are: [-0.541 -1.307]\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A3_e = np.real_if_close(A3_e)\n",
      "\n",
      "print 'The proportion of variance explained by the first principal component is:', round(A3_e[1] / A3_e.sum(),3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The proportion of variance explained by the first principal component is: 0.736\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Question 4 (10 points)**.\n",
      "\n",
      "Find the minimum of the following quadratic function on $\\mathbb{R}^2$ \n",
      "\n",
      "$$f(x) = x^TAx +b^Tx +c$$\n",
      "where\n",
      "$$A = \\left(\\begin{matrix}13&5\\\\5&7\\end{matrix}\\right), b = \\left(\\begin{matrix}1\\\\1\\end{matrix}\\right) \\textrm {and } c = 2$$\n",
      "\n",
      "Under the constraints:\n",
      "$$g(x) = 2x_1-5x_2=2 \\;\\;\\;\\;\\;\\; \\textrm{ and } \\;\\;\\;\\;\\;\\; h(x) = x_1+x_2=1$$\n",
      "\n",
      "1. Use a matrix decomposition method to find the minimum of the *unconstrained* problem without using `scipy.optimize` (Use library functions - no need to code your own). Note: for full credit you should exploit matrix structure. (3 points)\n",
      "2. Find the solution using constrained optimization with the `scipy.optimize` package. (3 points)\n",
      "2. Use Lagrange multipliers and solve the resulting set of equations directly without using `scipy.optimize`. (4 points)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "import scipy.optimize as opt"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Take derivative of f.  The minimum must occur where 2*A*x = -b.  Use eigendecomposition to invert A?\n",
      "\n",
      "b4 = np.array([1,1])\n",
      "A4 = np.array([[13,5],[5,7]])\n",
      "\n",
      "e4, V4 = la.eig(A4)\n",
      "lam_inv = np.zeros((2,2))\n",
      "lam_inv[0,0] = np.real_if_close(1/e4[0])\n",
      "lam_inv[1,1] = np.real_if_close(1/e4[1])\n",
      "\n",
      "print 'The unconstrained minimum occurs at:'\n",
      "print -0.5 * np.dot(V4,np.dot(lam_inv,np.dot(V4.T,b4)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The unconstrained minimum occurs at:\n",
        "[-0.015 -0.061]\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font color = 'green',size=4pt>Eigendecomposition is actually the worst choice.  Use Cholesky.  -1 </font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cons = ({'type': 'eq', 'fun': lambda x:  2*x[0] - 5*x[1] - 2},\n",
      "...     {'type': 'eq', 'fun': lambda x:    x[0] +   x[1] - 1})\n",
      "\n",
      "A = np.array([[13,5],[5,7]])\n",
      "b = np.array([1,1])\n",
      "\n",
      "def f(X):\n",
      "    return np.dot(X.T,np.dot(A,X)) + np.dot(b,X) + 2\n",
      "\n",
      "print opt.minimize(f, (2,0),constraints=cons)\n",
      "print \n",
      "print 'The minimum occurs at X = (1,0)'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'opt' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-20-08cb33e9a3d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'The minimum occurs at X = (1,0)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'opt' is not defined"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The function f is equivalent to: $13x_1^2 + 7x_2^2 + 10x_1x_2 + x_1 + x_2 + 2$.  The gradient of $f$ must be equal to the gradients of the constraints (up to scalar quantities $\\lambda_1, \\lambda_2$), so we set up the Lagrangian and take derivatives with respect to all unknowns.  This leads to a system of equations:\n",
      "\n",
      "\\begin{align*}\n",
      "26x_1 + 10x_2 + 1 - 2\\lambda_1 -\\lambda_2 &= 0 \\\\\n",
      "10x_1 + 14x_2 + 1 + 5\\lambda_1 -\\lambda_2 &= 0 \\\\\n",
      "2x_1 - 5x_2 - 2 &= 0 \\\\\n",
      "x_1 + x_2 - 1 &= 0 \\\\\n",
      "\\end{align*}"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test1 = np.array([[26,10,-2,-1],[10,14,5,-1],[2,-5,0,0],[1,1,0,0]])\n",
      "test2 = np.array([-1,-1,2,1])\n",
      "\n",
      "print test1, '\\n\\n', test2, '\\n'\n",
      "print la.lstsq(test1, test2)[0]\n",
      "print \n",
      "print 'We see that this is satisfied with x_1 = 1, x_2 = 0.  The Lagrange multipliers are 2.286 and 22.429.'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Question 5 (10 points)**. \n",
      "\n",
      "Consider the linear transformation $f(x)$ on $\\mathbb{R}^3$ that takes the standard basis $\\left\\{e_1,e_2,e_3\\right\\}$ to $\\left\\{v_1,v_2,v_3\\right\\}$ where\n",
      "\n",
      "$$v_1=\\left(\\begin{matrix}10\\\\-10\\\\16\\end{matrix}\\right), v_2=\\left(\\begin{matrix}2\\\\-5\\\\20\\end{matrix}\\right) \\textrm {and } v_3=\\left(\\begin{matrix}1\\\\-4\\\\13\\end{matrix}\\right)$$\n",
      "\n",
      "1. Write a matrix $A$ that represents the same linear transformaton. (2 points)\n",
      "\n",
      "2. Compute the rank of $A$ (use any method you like). (2 points)\n",
      "\n",
      "3. Find the eigenvalues and eigenvectors of $A$. (2 points)\n",
      "\n",
      "4. What is the matrix representation of $f$ with respect to the eigenbasis? (4 points)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A = np.array([[10, 2, 1],[-10,-5,-4],[16,20,13]])\n",
      "print A"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = np.linalg.matrix_rank(A)\n",
      "print 'The rank of A is', r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "e_A, V_A = la.eig(A)\n",
      "\n",
      "print 'The eigenvalues of A are:', np.real_if_close(e_A)\n",
      "print 'The eigenvectors of A are:' \n",
      "print V_A\n",
      "print 'where each column is an eigenvector.'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'The matrix representation of f with respect to the eigenbasis is P * Lambda, assuming the'\n",
      "print 'eigendecomposition of A = P * Lambda * P**-1'\n",
      "print \n",
      "print np.dot(V_A, np.diag(np.real_if_close(e_A)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font color = 'green',size=4pt>diag(eigenvalues)!  -4</font>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Question 6 (10 points)**\n",
      "\n",
      "Given the the function $f(x) = \\frac{1}{2} x^TAx + b^Tx$ where\n",
      "\n",
      "\\begin{align}\n",
      "A = \\left(\\begin{matrix}13&5&-3\\\\5&11&7\\\\-3&7&20\\end{matrix}\\right) \n",
      ", \\ b = \\left(\\begin{matrix}1\\\\1\\\\1\\end{matrix}\\right),\n",
      "\\end{align}\n",
      "\n",
      "complete the following code to find the first 3 vector directions for a conjugate gradient *descent* algorithm.\n",
      "\n",
      "Hint: Recall from linear algebra that the projection of $v$ on $u$ is \n",
      "\n",
      "$$\n",
      "\\frac{v \\cdot u}{u \\cdot u}u\n",
      "$$\n",
      "and that $u$ is conjugate to $v$ with respect to $A$ if \n",
      "$$Av\\cdot u = 0$$\n",
      "\n",
      "Also, recall that the gradient at $x_k$ of the quadratic function $f$ is given by $Ax_k + b$ since\n",
      "\n",
      "\\begin{align}\n",
      "\\dfrac{\\partial (x^TAx)}{\\partial x} &= \\dfrac{\\partial (x^T)^T}{\\partial x}\\dfrac{\\partial (x^Ty)}{\\partial x} +  \\dfrac{\\partial y^T}{\\partial x} \\dfrac{\\partial (x^Ty)}{\\partial y}\n",
      "   & \\text{chain rule with $y=Ax$} \\\\\n",
      "&= y + \\dfrac{\\partial (x^TA^T)}{\\partial x} \\dfrac{\\partial (x^Ty)}{\\partial y} & \\text{using $\\dfrac{\\partial (x^Ty)}{\\partial x} = y$} \\\\\n",
      "&= y + A^T\\dfrac{\\partial (y^Tx)}{\\partial y} & \\text{using $x^Ty = y^Tx$} \\\\\n",
      "&= Ax + A^Tx \\\\\n",
      "&= (A+A^T)x \\\\\n",
      "&= 2Ax & \\text{if $A$ is symmetric}\n",
      "\\end{align}\n",
      "\n",
      "\n",
      "<p>\n",
      "<font color=red>There are two lines of code to complete: the correction term in the function next_p, and the initial value of p = p0 in the main body of code.</font></p>\n",
      "\n",
      "<p>\n",
      "<font color=red>We do not expect this algorithm to converge in $3$ steps, and it is very primitive compared to scipy's implementation.  Do not be alarmed if you try to match solutions and fail.</font></p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def next_x (A,x,b,p):\n",
      "    return x + ((np.dot(p,-b))/(np.dot(p,A.dot(p))))*p # returns x_{k+1} given x_k, p_k, A and b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def next_p(A,x,b,ps):\n",
      "    correction = np.zeros_like(x)\n",
      "    for i in range(len(ps)):\n",
      "        correction +=          # Fill in this line (7 points)\n",
      "    \n",
      "    return -b - A.dot(x) - correction \n",
      "                                       \n",
      "# Complete the indicated line above with the correction term so that this function returns \n",
      "# the gradient at x minus the correction term that makes the new p conjugate to all the others"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A = np.array([[13,5,-3],[5,11,7],[-3,7,20]])   # Value of matrix A\n",
      "b = np.array([1,1,1])                           # Value of b\n",
      "x0 = np.array([0,0,0])                          # Initial guess for xmin\n",
      "\n",
      "p0 =                   # fill in p0 (3 points)\n",
      "\n",
      "x = x0 # initializes x for the for loop \n",
      "p = p0 # initializes p for the for loop\n",
      "ps = []  # start list to store the conjugate vectors\n",
      "ps.append(p0) # store first vector\n",
      "\n",
      "for i in range(2):\n",
      "    x = next_x(A,x,b,p)   # gets x_{k+1}\n",
      "    p = next_p(A,x,b,ps)  # computes p_{k+1}\n",
      "    ps.append(p)          # stores p_{k+1} in list\n",
      "\n",
      "ps  # prints the list of three vectors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font color = 'green',size=4pt>10</font>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- <font color='blue', size=4pt>Total deductions for Q1-Q3 = -4 </font>\n",
      "- <font color = 'green',size=4pt>Total Points Deducted Q4-Q6: -15</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}