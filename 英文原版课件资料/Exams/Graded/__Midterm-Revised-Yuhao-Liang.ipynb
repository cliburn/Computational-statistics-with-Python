{
 "metadata": {
  "name": "",
  "signature": "sha256:efb6987a49455c2247c5d08cb5cfe32e215b9ccc4a5dd02051903cc217d21d5b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Instructions\n",
      "----\n",
      "\n",
      "This is a \"closed book\" examination - in particular, you are not to use any resources outside of this notebook (except possibly pen and paper). You may consult help from within the notebook using ? but not any online references. Violation of any of these exam rules is a violation of the University's honor code and will result in penalty under that code.\n",
      "\n",
      "\n",
      "You have 1 hour and 45 minutes to complete the exam.\n",
      "\n",
      "- <font color=red>Use a new cell for different parts of a question</font>\n",
      "- <font color=red>The maximum score for the mid-terms is 60</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "import glob\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import scipy.linalg as la\n",
      "%matplotlib inline\n",
      "plt.style.use('ggplot')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 236
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 237
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rpy2.ipython"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The rpy2.ipython extension is already loaded. To reload it, use:\n",
        "  %reload_ext rpy2.ipython\n"
       ]
      }
     ],
     "prompt_number": 238
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 238
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Question 1 (10 points)**. \n",
      "\n",
      "Given the 2 matrices\n",
      "```\n",
      "A = np.array([[1,2,3],[4,5,6]])\n",
      "B = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
      "```\n",
      "\n",
      "Perform matrix multiplication of `A` and `B` using the following methods:\n",
      "\n",
      "1. Using nested `for` loops without the `dot` function (4 points)\n",
      "2. Using numpy (2 points)\n",
      "3. Using R (start the first line of a new cell with %%R). You should pass in the A and B matrices defined in Python for full marks, but partial credit will be given if you redefine them in R (4 points)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A = np.array([[1,2,3],[4,5,6]])\n",
      "B = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 239
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#1\n",
      "C = np.zeros(shape=(2,4))\n",
      "\n",
      "for i in range(2):\n",
      "    for j in range(4):\n",
      "        C[i,j] = sum(A[i,:]*B[:,j])\n",
      "\n",
      "print C\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 38.000  44.000  50.000  56.000]\n",
        " [ 83.000  98.000  113.000  128.000]]\n"
       ]
      }
     ],
     "prompt_number": 240
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#2\n",
      "print np.dot(A,B)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 38  44  50  56]\n",
        " [ 83  98 113 128]]\n"
       ]
      }
     ],
     "prompt_number": 241
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "%%R\n",
      "\n",
      "A = rbind(c(1,2,3),c(4,5,6))\n",
      "B = rbind(c(1,2,3,4),c(5,6,7,8),c(9,10,11,12))\n",
      "A %*% B\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "     [,1] [,2] [,3] [,4]\n",
        "[1,]   38   44   50   56\n",
        "[2,]   83   98  113  128\n"
       ]
      }
     ],
     "prompt_number": 242
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font color=blue>Grade (+/- comments)</font>\n",
      "\n",
      "\\-1 for not passing values in"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Question 2 (10 points)**. \n",
      "\n",
      "1. Read the `iris.csv` data set into a Pandas DataFrame. Dispaly the first 4 lines of the DataFrame. (2 points)\n",
      "2. Create a new DataFrame showing the mean `SepalLength`, `SepalWidth`, `PetalLength` and `PetalWidth` for the 3 different types of irises. (4 points)\n",
      "3. Make a scatter plot of `SepalLength` against `PetalLength` where each species is assigned a different color. (4 points)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! head -n6 iris.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "SepalLength,SepalWidth,PetalLength,PetalWidth,Name\r\n",
        "5.1,3.5,1.4,0.2,Iris-setosa\r\n",
        "4.9,3.0,1.4,0.2,Iris-setosa\r\n",
        "4.7,3.2,1.3,0.2,Iris-setosa\r\n",
        "4.6,3.1,1.5,0.2,Iris-setosa\r\n",
        "5.0,3.6,1.4,0.2,Iris-setosa\r\n"
       ]
      }
     ],
     "prompt_number": 243
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#1\n",
      "import csv\n",
      "df = pd.DataFrame([rows for rows in csv.reader(open('iris.csv'))])\n",
      "\n",
      "iris = df.ix[1:,]\n",
      "iris.columns = df.ix[0,:]\n",
      "#First 4 lines of data frame\n",
      "iris.ix[:4,]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>SepalLength</th>\n",
        "      <th>SepalWidth</th>\n",
        "      <th>PetalLength</th>\n",
        "      <th>PetalWidth</th>\n",
        "      <th>Name</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 5.1</td>\n",
        "      <td> 3.5</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 4.9</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 4.7</td>\n",
        "      <td> 3.2</td>\n",
        "      <td> 1.3</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 4.6</td>\n",
        "      <td> 3.1</td>\n",
        "      <td> 1.5</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 244,
       "text": [
        "0 SepalLength SepalWidth PetalLength PetalWidth         Name\n",
        "1         5.1        3.5         1.4        0.2  Iris-setosa\n",
        "2         4.9        3.0         1.4        0.2  Iris-setosa\n",
        "3         4.7        3.2         1.3        0.2  Iris-setosa\n",
        "4         4.6        3.1         1.5        0.2  Iris-setosa"
       ]
      }
     ],
     "prompt_number": 244
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#2\n",
      "var_list = ['SepalLength', 'SepalWidth', 'PetalLength' , 'PetalWidth']\n",
      "data_mean = [[np.mean(np.float64(iris.ix[iris.ix[:,'Name'] == s,c])) for c in var_list]  for s in set(iris.ix[:,'Name'])]    \n",
      "\n",
      "iris_mean = pd.DataFrame(data_mean)\n",
      "iris_mean.columns = iris.columns[:-1]\n",
      "iris_mean.index = set(iris.ix[:,'Name'])\n",
      "iris_mean"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>SepalLength</th>\n",
        "      <th>SepalWidth</th>\n",
        "      <th>PetalLength</th>\n",
        "      <th>PetalWidth</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Iris-virginica</th>\n",
        "      <td> 6.588</td>\n",
        "      <td> 2.974</td>\n",
        "      <td> 5.552</td>\n",
        "      <td> 2.026</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Iris-setosa</th>\n",
        "      <td> 5.006</td>\n",
        "      <td> 3.418</td>\n",
        "      <td> 1.464</td>\n",
        "      <td> 0.244</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Iris-versicolor</th>\n",
        "      <td> 5.936</td>\n",
        "      <td> 2.770</td>\n",
        "      <td> 4.260</td>\n",
        "      <td> 1.326</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 245,
       "text": [
        "0                SepalLength  SepalWidth  PetalLength  PetalWidth\n",
        "Iris-virginica         6.588       2.974        5.552       2.026\n",
        "Iris-setosa            5.006       3.418        1.464       0.244\n",
        "Iris-versicolor        5.936       2.770        4.260       1.326"
       ]
      }
     ],
     "prompt_number": 245
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#3\n",
      "col = pd.DataFrame(range(3)).T\n",
      "col.columns = list(set(iris.ix[:,'Name']))\n",
      "\n",
      "plt.scatter(np.float64(iris.ix[:,'SepalLength']),np.float64(iris.ix[:,'PetalLength']),c = col.ix[0,iris.ix[:,'Name']]);\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEECAYAAADeaATWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7fe296b80ad0>"
       ]
      }
     ],
     "prompt_number": 246
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Question 3 (10 points)**.\n",
      "\n",
      "Given the following covariance matrix\n",
      "```python\n",
      "A = np.array([[2,1],[1,4]])\n",
      "```\n",
      "\n",
      "1. Show that the eigenvectors of $A$ are orthogonal. (2 points)\n",
      "2. What is the vector representing the first principal component direction? (2 points)\n",
      "3. Find $A^{-1}$ without performing a matrix inversion. (2 points)\n",
      "4. What are the coordinates of the data points (0, 1) and (1, 1) in the standard basis expressed as coordinates of the principal components? (2 points)\n",
      "5. What is the proportion of variance explained if we keep only the projection onto the first principal component? (2 points)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.linalg as la"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 247
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A = np.array([[2,1],[1,4]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 248
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#1\n",
      "e,V = la.eig(A)\n",
      "\n",
      "print np.inner(V[:,0],V[:,1])\n",
      "print \"Inner product is 0 means they are orthogonal\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0\n",
        "Inner product is 0 means they are orthogonal\n"
       ]
      }
     ],
     "prompt_number": 249
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#2\n",
      "print \"The eigenvector with biggest eigenvalue is the vector representing the first principal component direction\"\n",
      "print V[:,np.argmax(e)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The eigenvector with biggest eigenvalue is the vector representing the first principal component direction\n",
        "[-0.383 -0.924]\n"
       ]
      }
     ],
     "prompt_number": 250
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#3\n",
      "A_inv = np.real_if_close(V.dot(np.diag(e**(-1))).dot(V.T))\n",
      "print A_inv\n",
      "print\n",
      "print A_inv.dot(A)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.571 -0.143]\n",
        " [-0.143  0.286]]\n",
        "\n",
        "[[ 1.000  0.000]\n",
        " [ 0.000  1.000]]\n"
       ]
      }
     ],
     "prompt_number": 251
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#4 The coordinates of the data points (0, 1) and (1, 1) in the standard basis expressed as coordinates of the principal components\n",
      "D = np.array([[0,1],\n",
      "              [1,1]])\n",
      "print V.dot(D)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[-0.383 -1.307]\n",
        " [-0.924 -0.541]]\n"
       ]
      }
     ],
     "prompt_number": 252
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font color=blue>Grade (+/- comments)</font>\n",
      "\n",
      "\\-1 multiply by v.T to move from standard to eigenvector basis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#5\n",
      "print \"The proportion of variance explained if we keep only the projection onto the first principal component\"\n",
      "print np.real_if_close(max(e)/sum(e))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The proportion of variance explained if we keep only the projection onto the first principal component\n",
        "0.735702260396\n"
       ]
      }
     ],
     "prompt_number": 253
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Question 4 (10 points)**.\n",
      "\n",
      "Find the minimum of the following quadratic function on $\\mathbb{R}^2$ \n",
      "\n",
      "$$f(x) = x^TAx +b^Tx +c$$\n",
      "where\n",
      "$$A = \\left(\\begin{matrix}13&5\\\\5&7\\end{matrix}\\right), b = \\left(\\begin{matrix}1\\\\1\\end{matrix}\\right) \\textrm {and } c = 2$$\n",
      "\n",
      "Under the constraints:\n",
      "$$g(x) = 2x_1-5x_2=2 \\;\\;\\;\\;\\;\\; \\textrm{ and } \\;\\;\\;\\;\\;\\; h(x) = x_1+x_2=1$$\n",
      "\n",
      "1. Use a matrix decomposition method to find the minimum of the *unconstrained* problem without using `scipy.optimize` (Use library functions - no need to code your own). Note: for full credit you should exploit matrix structure. (3 points)\n",
      "2. Find the solution using constrained optimization with the `scipy.optimize` package. (3 points)\n",
      "2. Use Lagrange multipliers and solve the resulting set of equations directly without using `scipy.optimize`. (4 points)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.optimize as opt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 254
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#1\n",
      "A = np.array([[13,5],\n",
      "              [5,7]])\n",
      "b = np.array([1.0,1.0]).T\n",
      "\n",
      "A_e, A_V = la.eig(A)\n",
      "A_e = np.real_if_close(A_e)\n",
      "print \"Eigenvalues of A\",A_e\n",
      "print \"Eigenvalues of A are all positive and we can use eigendecomposition\"\n",
      "s1 = A_V.dot(np.diag(A_e**(-1))).dot(A_V.T).dot(b.T/2)\n",
      "print \"Solution \", s1\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Eigenvalues of A [ 15.831  4.169]\n",
        "Eigenvalues of A are all positive and we can use eigendecomposition\n",
        "Solution  [ 0.015  0.061]\n"
       ]
      }
     ],
     "prompt_number": 255
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font color = 'green',size=4pt>Use Cholesky!  -1</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#2\n",
      "def func_q(x):\n",
      "    return x.T.dot(A).dot(x) + b.T.dot(x) + 2\n",
      "\n",
      "cons = ({'type': 'eq', 'fun': lambda x:  2 * x[0] - 5 * x[1] - 2},\n",
      "        {'type': 'eq', 'fun': lambda x:  x[0] + x[1] - 1})\n",
      "\n",
      "x0 = b\n",
      "\n",
      "sol1 = opt.minimize(func_q,x0,constraints = cons)\n",
      "sol1.x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 256,
       "text": [
        "array([ 1.000,  0.000])"
       ]
      }
     ],
     "prompt_number": 256
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sympy\n",
      "\n",
      "x,y,l,r = sympy.symbols('x y l r')\n",
      "X = np.array([x,y])\n",
      "f = X.T.dot(A).dot(X) + b.T.dot(X) + 2\n",
      "lrg = f + l*(2*X[0]-5*X[1]-2) + r*(X[0]+X[1]-1)\n",
      "grad = [sympy.diff(lrg,s) for s in [x,y,l,r]]\n",
      "print \"The gradient of f + constrants \"\n",
      "print grad\n",
      "print \n",
      "#After solve the linear systems we can get the result\n",
      "grad_A = np.array([[26,10,2,1],\n",
      "                   [10,14,-5,1],\n",
      "                   [2,-5,0,0],\n",
      "                   [1,1,0,0]])\n",
      "grad_b = np.array([-1,-1,2,1])\n",
      "\n",
      "\n",
      "print \"Solution of the linear system \",np.linalg.solve(grad_A,grad_b)[:2]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The gradient of f + constrants \n",
        "[2*l + r + 26*x + 10*y + 1.0, -5*l + r + 10*x + 14*y + 1.0, 2*x - 5*y - 2, x + y - 1]\n",
        "\n",
        "Solution of the linear system  [ 1.000 -0.000]\n"
       ]
      }
     ],
     "prompt_number": 257
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Question 5 (10 points)**. \n",
      "\n",
      "Consider the linear transformation $f(x)$ on $\\mathbb{R}^3$ that takes the standard basis $\\left\\{e_1,e_2,e_3\\right\\}$ to $\\left\\{v_1,v_2,v_3\\right\\}$ where\n",
      "\n",
      "$$v_1=\\left(\\begin{matrix}10\\\\-10\\\\16\\end{matrix}\\right), v_2=\\left(\\begin{matrix}2\\\\-5\\\\20\\end{matrix}\\right) \\textrm {and } v_3=\\left(\\begin{matrix}1\\\\-4\\\\13\\end{matrix}\\right)$$\n",
      "\n",
      "1. Write a matrix $A$ that represents the same linear transformaton. (2 points)\n",
      "\n",
      "2. Compute the rank of $A$ (use any method you like). (2 points)\n",
      "\n",
      "3. Find the eigenvalues and eigenvectors of $A$. (2 points)\n",
      "\n",
      "4. What is the matrix representation of $f$ with respect to the eigenbasis? (4 points)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "v1 = np.array([10,-10,16])\n",
      "v2 = np.array([2,-5,20])\n",
      "v3 = np.array([1,-4,13])\n",
      "A = np.vstack((v1,v2,v3)).T\n",
      "A"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 258,
       "text": [
        "array([[ 10,   2,   1],\n",
        "       [-10,  -5,  -4],\n",
        "       [ 16,  20,  13]])"
       ]
      }
     ],
     "prompt_number": 258
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.linalg.matrix_rank(A)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 259,
       "text": [
        "3"
       ]
      }
     ],
     "prompt_number": 259
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Ae,AV = la.eig(A)\n",
      "Ae = np.real_if_close(Ae)\n",
      "print Ae\n",
      "print AV"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 9.000  3.000  6.000]\n",
        "[[-0.577 -0.000 -0.120]\n",
        " [ 0.577  0.447 -0.241]\n",
        " [-0.577 -0.894  0.963]]\n"
       ]
      }
     ],
     "prompt_number": 260
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.diag(Ae)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 261,
       "text": [
        "array([[ 9.000,  0.000,  0.000],\n",
        "       [ 0.000,  3.000,  0.000],\n",
        "       [ 0.000,  0.000,  6.000]])"
       ]
      }
     ],
     "prompt_number": 261
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Question 6 (10 points)**\n",
      "\n",
      "Given the the function $f(x) = \\frac{1}{2} x^TAx + b^Tx$ where\n",
      "\n",
      "\\begin{align}\n",
      "A = \\left(\\begin{matrix}13&5&-3\\\\5&11&7\\\\-3&7&20\\end{matrix}\\right) \n",
      ", \\ b = \\left(\\begin{matrix}1\\\\1\\\\1\\end{matrix}\\right),\n",
      "\\end{align}\n",
      "\n",
      "complete the following code to find the first 3 vector directions for a conjugate gradient *descent* algorithm.\n",
      "\n",
      "Hint: Recall from linear algebra that the projection of $v$ on $u$ is \n",
      "\n",
      "$$\n",
      "\\frac{v \\cdot u}{u \\cdot u}u\n",
      "$$\n",
      "and that $u$ is conjugate to $v$ with respect to $A$ if \n",
      "$$Av\\cdot u = 0$$\n",
      "\n",
      "Also, recall that the gradient at $x_k$ of the quadratic function $f$ is given by $Ax_k + b$ since\n",
      "\n",
      "\\begin{align}\n",
      "\\dfrac{\\partial (x^TAx)}{\\partial x} &= \\dfrac{\\partial (x^T)^T}{\\partial x}\\dfrac{\\partial (x^Ty)}{\\partial x} +  \\dfrac{\\partial y^T}{\\partial x} \\dfrac{\\partial (x^Ty)}{\\partial y}\n",
      "   & \\text{chain rule with $y=Ax$} \\\\\n",
      "&= y + \\dfrac{\\partial (x^TA^T)}{\\partial x} \\dfrac{\\partial (x^Ty)}{\\partial y} & \\text{using $\\dfrac{\\partial (x^Ty)}{\\partial x} = y$} \\\\\n",
      "&= y + A^T\\dfrac{\\partial (y^Tx)}{\\partial y} & \\text{using $x^Ty = y^Tx$} \\\\\n",
      "&= Ax + A^Tx \\\\\n",
      "&= (A+A^T)x \\\\\n",
      "&= 2Ax & \\text{if $A$ is symmetric}\n",
      "\\end{align}\n",
      "\n",
      "\n",
      "<p>\n",
      "<font color=red>There are two lines of code to complete: the correction term in the function next_p, and the initial value of p = p0 in the main body of code.</font></p>\n",
      "\n",
      "<p>\n",
      "<font color=red>We do not expect this algorithm to converge in $3$ steps, and it is very primitive compared to scipy's implementation.  Do not be alarmed if you try to match solutions and fail.</font></p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def next_x (A,x,b,p):\n",
      "    return x + ((np.dot(p,-b))/(np.dot(p,A.dot(p))))*p # returns x_{k+1} given x_k, p_k, A and b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 262
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def next_p(A,x,b,ps):\n",
      "    correction = np.zeros_like(x)\n",
      "    for i in range(len(ps)):\n",
      "        correction += - (ps[i].T.dot(A).dot(b + A.dot(x))*1.0/ ps[i].T.dot(A).dot(ps[i])) * ps[i] # Fill in this line (7 points)\n",
      "    \n",
      "    return -b - A.dot(x) - correction \n",
      "                                       \n",
      "# Complete the indicated line above with the correction term so that this function returns \n",
      "# the gradient at x minus the correction term that makes the new p conjugate to all the others"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 263
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font color = 'green',size=4pt>Yay!  It's correct, except that you want -gradient for descent.  Full credit awarded, but be careful in future.</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A = np.array([[13,5,-3],[5,11,7],[-3,7,20]])   # Value of matrix A\n",
      "b = np.array([1,1,1])                           # Value of b\n",
      "x0 = np.array([0,0,0])                          # Initial guess for xmin\n",
      "\n",
      "p0 =  b + A.dot(x0)          # fill in p0 (3 points)\n",
      "\n",
      "x = x0 # initializes x for the for loop \n",
      "p = p0 # initializes p for the for loop\n",
      "ps = []  # start list to store the conjugate vectors\n",
      "ps.append(p0) # store first vector\n",
      "\n",
      "for i in range(2):\n",
      "    x = next_x(A,x,b,p)   # gets x_{k+1}\n",
      "    p = next_p(A,x,b,ps)  # computes p_{k+1}\n",
      "    ps.append(p)          # stores p_{k+1} in list\n",
      "\n",
      "ps  # prints the list of three vectors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 264,
       "text": [
        "[array([1, 1, 1]), array([-6,  2,  3]), array([ 5, -1, -2])]"
       ]
      }
     ],
     "prompt_number": 264
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- <font color='blue', size=4pt>Total deductions for Q1-Q3 = -2 </font>\n",
      "- <font color = 'green',size=4pt>Total Points Deducted Q4-Q6: -1</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}