{
 "metadata": {
  "name": "",
  "signature": "sha256:35f2a871808b25569064debe70a9ae96ef3d413ca0da00502aa2eb1ae0092123"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Instructions\n",
      "----\n",
      "\n",
      "This is a \"closed book\" examination - in particular, you are not to use any resources outside of this notebook (except possibly pen and paper). You may consult help from within the notebook using ? but not any online references. Violation of any of these exam rules is a violation of the University's honor code and will result in penalty under that code.\n",
      "\n",
      "\n",
      "You have 1 hour and 45 minutes to complete the exam.\n",
      "\n",
      "- <font color=red>Use a new cell for different parts of a question</font>\n",
      "- <font color=red>The maximum score for the mid-terms is 60</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "import glob\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import scipy.linalg as la\n",
      "%matplotlib inline\n",
      "plt.style.use('ggplot')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rpy2.ipython"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Question 1 (10 points)**. \n",
      "\n",
      "Given the 2 matrices\n",
      "```\n",
      "A = np.array([[1,2,3],[4,5,6]])\n",
      "B = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
      "```\n",
      "\n",
      "Perform matrix multiplication of `A` and `B` using the following methods:\n",
      "\n",
      "1. Using nested `for` loops without the `dot` function (4 points)\n",
      "2. Using numpy (2 points)\n",
      "3. Using R (start the first line of a new cell with %%R). You should pass in the A and B matrices defined in Python for full marks, but partial credit will be given if you redefine them in R (4 points)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A = np.array([[1,2,3],[4,5,6]])\n",
      "B = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## 1\n",
      "m = np.shape(A)[0]\n",
      "n = np.shape(B)[1]\n",
      "Mul = np.zeros((m,n))\n",
      "for i in range(m):\n",
      "    for j in range(n):\n",
      "        Mul[i,j] = 0\n",
      "        for k in range(np.shape(A)[1]):\n",
      "            Mul[i,j] += A[i,k]*B[k,j]\n",
      "print \"The multiplication using nested loop is:\\n\", Mul"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The multiplication using nested loop is:\n",
        "[[ 38.000  44.000  50.000  56.000]\n",
        " [ 83.000  98.000  113.000  128.000]]\n"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## 2\n",
      "print \"The multiplication using numpy function is:\\n\", np.dot(A,B)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The multiplication using numpy function is:\n",
        "[[ 38  44  50  56]\n",
        " [ 83  98 113 128]]\n"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "%%R \n",
      "A = matrix(seq(1,6,1),  nrow = 2, byrow=T)\n",
      "B = matrix(seq(1,12,1),  nrow = 3,  byrow=T)\n",
      "crossprod(t(A),B)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "     [,1] [,2] [,3] [,4]\n",
        "[1,]   38   44   50   56\n",
        "[2,]   83   98  113  128\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font color=blue>Grade (+/- comments)</font>\n",
      "\n",
      "\\-1 for not passing values in"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### CORRECTION ### "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R -i A,B\n",
      "crossprod(t(A),B)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Question 2 (10 points)**. \n",
      "\n",
      "1. Read the `iris.csv` data set into a Pandas DataFrame. Dispaly the first 4 lines of the DataFrame. (2 points)\n",
      "2. Create a new DataFrame showing the mean `SepalLength`, `SepalWidth`, `PetalLength` and `PetalWidth` for the 3 different types of irises. (4 points)\n",
      "3. Make a scatter plot of `SepalLength` against `PetalLength` where each species is assigned a different color. (4 points)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! head -n6 iris.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "SepalLength,SepalWidth,PetalLength,PetalWidth,Name\r\n",
        "5.1,3.5,1.4,0.2,Iris-setosa\r\n",
        "4.9,3.0,1.4,0.2,Iris-setosa\r\n",
        "4.7,3.2,1.3,0.2,Iris-setosa\r\n",
        "4.6,3.1,1.5,0.2,Iris-setosa\r\n",
        "5.0,3.6,1.4,0.2,Iris-setosa\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris = pd.read_csv('iris.csv')\n",
      "iris.head(4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>SepalLength</th>\n",
        "      <th>SepalWidth</th>\n",
        "      <th>PetalLength</th>\n",
        "      <th>PetalWidth</th>\n",
        "      <th>Name</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 5.1</td>\n",
        "      <td> 3.5</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 4.9</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 4.7</td>\n",
        "      <td> 3.2</td>\n",
        "      <td> 1.3</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 4.6</td>\n",
        "      <td> 3.1</td>\n",
        "      <td> 1.5</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "   SepalLength  SepalWidth  PetalLength  PetalWidth         Name\n",
        "0          5.1         3.5          1.4         0.2  Iris-setosa\n",
        "1          4.9         3.0          1.4         0.2  Iris-setosa\n",
        "2          4.7         3.2          1.3         0.2  Iris-setosa\n",
        "3          4.6         3.1          1.5         0.2  Iris-setosa"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris.groupby('Name').mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>SepalLength</th>\n",
        "      <th>SepalWidth</th>\n",
        "      <th>PetalLength</th>\n",
        "      <th>PetalWidth</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Name</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Iris-setosa</th>\n",
        "      <td> 5.006</td>\n",
        "      <td> 3.418</td>\n",
        "      <td> 1.464</td>\n",
        "      <td> 0.244</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Iris-versicolor</th>\n",
        "      <td> 5.936</td>\n",
        "      <td> 2.770</td>\n",
        "      <td> 4.260</td>\n",
        "      <td> 1.326</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Iris-virginica</th>\n",
        "      <td> 6.588</td>\n",
        "      <td> 2.974</td>\n",
        "      <td> 5.552</td>\n",
        "      <td> 2.026</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "                 SepalLength  SepalWidth  PetalLength  PetalWidth\n",
        "Name                                                             \n",
        "Iris-setosa            5.006       3.418        1.464       0.244\n",
        "Iris-versicolor        5.936       2.770        4.260       1.326\n",
        "Iris-virginica         6.588       2.974        5.552       2.026"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xs = iris.SepalLength\n",
      "setosa = iris[iris.Name=='Iris-setosa']\n",
      "xs_s = setosa.SepalLength\n",
      "ys_s = setosa.PetalLength\n",
      "plt.scatter(xs_s, ys_s, c='r')\n",
      "\n",
      "versicolor = iris[iris.Name=='Iris-versicolor']\n",
      "xs_v = versicolor.SepalLength\n",
      "ys_v = versicolor.PetalLength\n",
      "plt.scatter(xs_v, ys_v, c='b')\n",
      "\n",
      "virginica = iris[iris.Name=='Iris-virginica']\n",
      "xs_vi = virginica.SepalLength\n",
      "ys_vi = virginica.PetalLength\n",
      "plt.scatter(xs_vi, ys_vi, c='g')\n",
      "plt.legend(('Iris-setosa', 'Iris-versicolor', 'Iris-virginica'), loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "<matplotlib.legend.Legend at 0x10c46d250>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEECAYAAADeaATWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEjBmMSJiBSMSZyISMGYxImIFOz/A22UKoPwjAgyAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x1117f6a50>"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Question 3 (10 points)**.\n",
      "\n",
      "Given the following covariance matrix\n",
      "```python\n",
      "A = np.array([[2,1],[1,4]])\n",
      "```\n",
      "\n",
      "1. Show that the eigenvectors of $A$ are orthogonal. (2 points)\n",
      "2. What is the vector representing the first principal component direction? (2 points)\n",
      "3. Find $A^{-1}$ without performing a matrix inversion. (2 points)\n",
      "4. What are the coordinates of the data points (0, 1) and (1, 1) in the standard basis expressed as coordinates of the principal components? (2 points)\n",
      "5. What is the proportion of variance explained if we keep only the projection onto the first principal component? (2 points)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.linalg as la"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A = np.array([[2,1],[1,4]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## 1\n",
      "e,V = la.eig(A)\n",
      "print \"The product V.T.V is identity: \\n\",V.T.dot(V), \"\\n So, the eigen vectors are orthogonal\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The product V.T.V is identity: \n",
        "[[ 1.000  0.000]\n",
        " [ 0.000  1.000]] \n",
        " So, the eigen vectors are orthogonal\n"
       ]
      }
     ],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## 2\n",
      "print \"The first principal component direction is where the eigen vector related to the \\\n",
      "maximum eigen value, which is given by:\\n\",V[:,np.argmax(e)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The first principal component direction is where the eigen vector related to the maximum eigen value, which is given by:\n",
        "[-0.383 -0.924]\n"
       ]
      }
     ],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## 3\n",
      "print np.real_if_close(V.dot(np.diag(e**(-1)).dot(V.T)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.571 -0.143]\n",
        " [-0.143  0.286]]\n"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## 4\n",
      "print \"(1,1) represented in principal components spacce:\", la.inv(V).dot([1,1])\n",
      "print \"(0,1) represented in principal components spacce:\", la.inv(V).dot([0,1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1,1) represented in principal components spacce: [-0.541 -1.307]\n",
        "(0,1) represented in principal components spacce: [ 0.383 -0.924]\n"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font color=blue>Grade (+/- comments)</font>\n",
      "\n",
      "No deductions, but you should use v.T instead of inv() since you know that v is orthogonal."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## 5\n",
      "idx = np.argsort(e)\n",
      "e = np.real_if_close(e[idx][::-1])\n",
      "print \"percent of variance explained by first principal component is:\", e[0]/sum(e)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "percent of variance explained by first principal component is: 0.735702260396\n"
       ]
      }
     ],
     "prompt_number": 127
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Question 4 (10 points)**.\n",
      "\n",
      "Find the minimum of the following quadratic function on $\\mathbb{R}^2$ \n",
      "\n",
      "$$f(x) = x^TAx +b^Tx +c$$\n",
      "where\n",
      "$$A = \\left(\\begin{matrix}13&5\\\\5&7\\end{matrix}\\right), b = \\left(\\begin{matrix}1\\\\1\\end{matrix}\\right) \\textrm {and } c = 2$$\n",
      "\n",
      "Under the constraints:\n",
      "$$g(x) = 2x_1-5x_2=2 \\;\\;\\;\\;\\;\\; \\textrm{ and } \\;\\;\\;\\;\\;\\; h(x) = x_1+x_2=1$$\n",
      "\n",
      "1. Use a matrix decomposition method to find the minimum of the *unconstrained* problem without using `scipy.optimize` (Use library functions - no need to code your own). Note: for full credit you should exploit matrix structure. (3 points)\n",
      "2. Find the solution using constrained optimization with the `scipy.optimize` package. (3 points)\n",
      "2. Use Lagrange multipliers and solve the resulting set of equations directly without using `scipy.optimize`. (4 points)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.optimize as opt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## 1\n",
      "A = np.array([[13,5], [5,7]])\n",
      "b = np.array([1,1])\n",
      "c =2\n",
      "U, s, V = la.svd(A)\n",
      "x = -(0.5)*(V.T.dot(la.inv(np.diag(s)).dot(U.T.dot(b))))\n",
      "print \"Optimized using matrix decomposition:\", x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Optimized using matrix decomposition: [-0.015 -0.061]\n"
       ]
      }
     ],
     "prompt_number": 129
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font color = 'green',size=4pt>Use Cholesky -1</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### CORRECTION ###\n",
      "## 1\n",
      "A = np.array([[13,5], [5,7]])\n",
      "b = np.array([1,1])\n",
      "c = 2\n",
      "L = la.cholesky(A)\n",
      "Linv = la.inv(L)\n",
      "x = -(0.5)*Linv.dot(Linv.T.dot(b))\n",
      "print \"Optimized using matrix decomposition:\", x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Optimized using matrix decomposition: [-0.015 -0.061]\n"
       ]
      }
     ],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## 2\n",
      "def f(x):\n",
      "    A = np.array([[13,5], [5,7]])\n",
      "    b = np.array([1,1])\n",
      "    c = 2\n",
      "    return x.T.dot(A.dot(x)) + b.T.dot(x) +c\n",
      "cons = ({'type': 'eq',\n",
      "         'fun': lambda x: np.array([2*x[0] -5*x[1] - 2])},\n",
      "         {'type': 'eq',\n",
      "         'fun': lambda x: np.array([x[0] + x[1] - 1])})\n",
      "optimized_cons = opt.minimize(f, [1,1], constraints = cons)\n",
      "print \"Optimized using scipy.optimize and the constraints is:\", optimized_cons.x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Optimized using scipy.optimize and the constraints is: [ 1.000  0.000]\n"
       ]
      }
     ],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## 3\n",
      "from sympy import symbols, solve, diff\n",
      "x, y, l1, l2 = symbols('x y l1 l2')\n",
      "f1 = 13*x + 5*y+1\n",
      "f2 = 5*x +7*y +1\n",
      "X =np.array([x,y])[:,None]\n",
      "f = 0.5*x*(13*x + 5*y) + x + 0.5*y*(5*x + 7*y) + y + 2\n",
      "#gradf = [[diff(f, x)], [diff(f,y)]]\n",
      "g = 2*x - 5*y -2\n",
      "h = x + y -1\n",
      "#solve((f1,f2), (x,y))\n",
      "gradfx = diff(f,x)\n",
      "gradfy = diff(f,y)\n",
      "a = gradfx -l1*diff(g,x)\n",
      "b = gradfy - l1*diff(g,y)\n",
      "c = gradfx - l2*diff(h,x)\n",
      "d = gradfy - l2*diff(h,y)\n",
      "#solve((a,b,g),(x,y,l1))\n",
      "#solve((a,b,c,d,g),(x,y,l1,l2,k))\n",
      "f"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 132,
       "text": [
        "0.5*x*(13*x + 5*y) + x + 0.5*y*(5*x + 7*y) + y + 2"
       ]
      }
     ],
     "prompt_number": 132
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font color = 'green',size=4pt>-2</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### CORRECTION ###\n",
      "## 3\n",
      "from sympy import symbols, solve, diff\n",
      "x, y, l1, l2 = symbols('x y l1 l2')\n",
      "X =np.array([x,y])[:,None]\n",
      "f = 0.5*(x*(13*x + 5*y) + y*(5*x + 7*y)) + x + y + 2\n",
      "gradfx = diff(f,x)\n",
      "gradfy = diff(f,y)\n",
      "a = gradfx - l1*diff(g,x)- l2*diff(h,x)\n",
      "b = gradfy - l1*diff(g,y)- l2*diff(h,y)\n",
      "g = 2*x - 5*y -2 #Constraint 1\n",
      "h = x + y -1     #Constraint 2\n",
      "solve((a,b,g, h),(x,y,l1,l2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 133,
       "text": [
        "{l1: 1.14285714285714, l2: 11.7142857142857, x: 1.00000000000000, y: 0.0}"
       ]
      }
     ],
     "prompt_number": 133
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Question 5 (10 points)**. \n",
      "\n",
      "Consider the linear transformation $f(x)$ on $\\mathbb{R}^3$ that takes the standard basis $\\left\\{e_1,e_2,e_3\\right\\}$ to $\\left\\{v_1,v_2,v_3\\right\\}$ where\n",
      "\n",
      "$$v_1=\\left(\\begin{matrix}10\\\\-10\\\\16\\end{matrix}\\right), v_2=\\left(\\begin{matrix}2\\\\-5\\\\20\\end{matrix}\\right) \\textrm {and } v_3=\\left(\\begin{matrix}1\\\\-4\\\\13\\end{matrix}\\right)$$\n",
      "\n",
      "1. Write a matrix $A$ that represents the same linear transformaton. (2 points)\n",
      "\n",
      "2. Compute the rank of $A$ (use any method you like). (2 points)\n",
      "\n",
      "3. Find the eigenvalues and eigenvectors of $A$. (2 points)\n",
      "\n",
      "4. What is the matrix representation of $f$ with respect to the eigenbasis? (4 points)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## 1\n",
      "A = np.array([[10,2,1],[-10,-5,-4], [16,20,13]])\n",
      "print \"The matrix representing the given transformation is:\\n\",A"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The matrix representing the given transformation is:\n",
        "[[ 10   2   1]\n",
        " [-10  -5  -4]\n",
        " [ 16  20  13]]\n"
       ]
      }
     ],
     "prompt_number": 134
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## 2\n",
      "print \"The rank of A is:\", np.linalg.matrix_rank(A)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The rank of A is: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3\n"
       ]
      }
     ],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## 3\n",
      "e,V = la.eig(A)\n",
      "print \"The Eigenvalues of A are:\", np.real_if_close(e)\n",
      "print \"The Eigenvectors of A are:\\n\", np.real_if_close(V)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The Eigenvalues of A are: [ 9.000  3.000  6.000]\n",
        "The Eigenvectors of A are:\n",
        "[[-0.577 -0.000 -0.120]\n",
        " [ 0.577  0.447 -0.241]\n",
        " [-0.577 -0.894  0.963]]\n"
       ]
      }
     ],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## 4\n",
      "print \"The matrix representation of f with respect to eigen basis is:\\n\"\n",
      "print V.dot(A.dot(V.T))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The matrix representation of f with respect to eigen basis is:\n",
        "\n",
        "[[ 4.703 -5.523  5.568]\n",
        " [ 1.995 -3.065  2.566]\n",
        " [-12.596  17.088 -15.975]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 137
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font color = 'green',size=4pt>diag(eigenvalues) -4</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### CORRECTION ###\n",
      "## 4\n",
      "print \"The matrix representation of f with respect to eigen basis is:\\n\"\n",
      "print np.real_if_close(np.diag(e))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The matrix representation of f with respect to eigen basis is:\n",
        "\n",
        "[[ 9.000  0.000  0.000]\n",
        " [ 0.000  3.000  0.000]\n",
        " [ 0.000  0.000  6.000]]\n"
       ]
      }
     ],
     "prompt_number": 138
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Question 6 (10 points)**\n",
      "\n",
      "Given the the function $f(x) = \\frac{1}{2} x^TAx + b^Tx$ where\n",
      "\n",
      "\\begin{align}\n",
      "A = \\left(\\begin{matrix}13&5&-3\\\\5&11&7\\\\-3&7&20\\end{matrix}\\right) \n",
      ", \\ b = \\left(\\begin{matrix}1\\\\1\\\\1\\end{matrix}\\right),\n",
      "\\end{align}\n",
      "\n",
      "complete the following code to find the first 3 vector directions for a conjugate gradient *descent* algorithm.\n",
      "\n",
      "Hint: Recall from linear algebra that the projection of $v$ on $u$ is \n",
      "\n",
      "$$\n",
      "\\frac{v \\cdot u}{u \\cdot u}u\n",
      "$$\n",
      "and that $u$ is conjugate to $v$ with respect to $A$ if \n",
      "$$Av\\cdot u = 0$$\n",
      "\n",
      "Also, recall that the gradient at $x_k$ of the quadratic function $f$ is given by $Ax_k + b$ since\n",
      "\n",
      "\\begin{align}\n",
      "\\dfrac{\\partial (x^TAx)}{\\partial x} &= \\dfrac{\\partial (x^T)^T}{\\partial x}\\dfrac{\\partial (x^Ty)}{\\partial x} +  \\dfrac{\\partial y^T}{\\partial x} \\dfrac{\\partial (x^Ty)}{\\partial y}\n",
      "   & \\text{chain rule with $y=Ax$} \\\\\n",
      "&= y + \\dfrac{\\partial (x^TA^T)}{\\partial x} \\dfrac{\\partial (x^Ty)}{\\partial y} & \\text{using $\\dfrac{\\partial (x^Ty)}{\\partial x} = y$} \\\\\n",
      "&= y + A^T\\dfrac{\\partial (y^Tx)}{\\partial y} & \\text{using $x^Ty = y^Tx$} \\\\\n",
      "&= Ax + A^Tx \\\\\n",
      "&= (A+A^T)x \\\\\n",
      "&= 2Ax & \\text{if $A$ is symmetric}\n",
      "\\end{align}\n",
      "\n",
      "\n",
      "<p>\n",
      "<font color=red>There are two lines of code to complete: the correction term in the function next_p, and the initial value of p = p0 in the main body of code.</font></p>\n",
      "\n",
      "<p>\n",
      "<font color=red>We do not expect this algorithm to converge in $3$ steps, and it is very primitive compared to scipy's implementation.  Do not be alarmed if you try to match solutions and fail.</font></p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def next_x (A,x,b,p):\n",
      "    return x + ((np.dot(p,-b))/(np.dot(p,A.dot(p))))*p # returns x_{k+1} given x_k, p_k, A and b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#def next_p(A,x,b,ps):\n",
      "#    correction = np.zeros_like(x)\n",
      "#    for i in range(len(ps)):\n",
      "#        correction += A[i,:].dot(ps[i])/(ps[i].dot(ps[i]))*ps[i]         # Fill in this line (7 points)\n",
      "#    \n",
      "#    return -b - A.dot(x) - correction \n",
      "                                       \n",
      "# Complete the indicated line above with the correction term so that this function returns \n",
      "# the gradient at x minus the correction term that makes the new p conjugate to all the others"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 140
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font color = 'green',size=4pt>Not quite.  -6</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### CORRECTION ### \n",
      "def next_p(A,x,b,ps):\n",
      "    correction = np.zeros_like(x)\n",
      "    for i in range(len(ps)):\n",
      "        #print ps[i]\n",
      "        correction += (ps[i].dot(A.dot(-b-A.dot(x))))/(ps[i].dot(A.dot(ps[i])))*ps[i]        # Fill in this line (7 points)\n",
      "    \n",
      "    return -b - A.dot(x) - correction \n",
      "                                       \n",
      "# Complete the indicated line above with the correction term so that this function returns \n",
      "# the gradient at x minus the correction term that makes the new p conjugate to all the others"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 141
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#A = np.array([[13,5,-3],[5,11,7],[-3,7,20]])   # Value of matrix A\n",
      "#b = np.array([1,1,1])                           # Value of b\n",
      "#x0 = np.array([0,0,0])                          # Initial guess for xmin\n",
      "\n",
      "#p0 = A[1,:]              # fill in p0 (3 points)\n",
      "\n",
      "#x = x0 # initializes x for the for loop \n",
      "#p = p0 # initializes p for the for loop\n",
      "#ps = []  # start list to store the conjugate vectors\n",
      "#ps.append(p0) # store first vector\n",
      "\n",
      "#for i in range(2):\n",
      "#    x = next_x(A,x,b,p)   # gets x_{k+1}\n",
      "#    p = next_p(A,x,b,ps)  # computes p_{k+1}\n",
      "#    ps.append(p)          # stores p_{k+1} in list\n",
      "\n",
      "#ps  # prints the list of three vectors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 142
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font color = 'green',size=4pt>-3</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### CORRECTION ### \n",
      "A = np.array([[13,5,-3],[5,11,7],[-3,7,20]])   # Value of matrix A\n",
      "b = np.array([1,1,1])                           # Value of b\n",
      "x0 = np.array([0,0,0])                          # Initial guess for xmin\n",
      "\n",
      "p0 = (- b - A.dot(x0)).astype(float)            # fill in p0 (3 points)\n",
      "x = x0 # initializes x for the for loop \n",
      "p = p0 # initializes p for the for loop\n",
      "ps = []  # start list to store the conjugate vectors\n",
      "ps.append(p0) # store first vector\n",
      "\n",
      "for i in range(2):\n",
      "    x = next_x(A,x,b,p)   # gets x_{k+1}\n",
      "    p = next_p(A,x,b,ps)  # computes p_{k+1}\n",
      "    ps.append(p)          # stores p_{k+1} in list\n",
      "\n",
      "ps  # prints the list of three vectors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 143,
       "text": [
        "[array([-1.000, -1.000, -1.000]),\n",
        " array([-0.312,  0.075,  0.123]),\n",
        " array([-0.066,  0.118, -0.072])]"
       ]
      }
     ],
     "prompt_number": 143
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- <font color='blue', size=4pt>Bonus for corrections Q1-Q3 = +0.5 </font>\n",
      "- <font color='blue', size=4pt>Total deductions for Q1-Q3 = -1 </font>\n",
      "- <font color = 'green',size=4pt>Total Points Deducted Q4-Q6: -16</font>\n",
      "- <font color = 'green',size=4pt>Bonus for corrections Q4-Q6: +8</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}