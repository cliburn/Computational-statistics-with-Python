{
 "metadata": {
  "name": "",
  "signature": "sha256:c65c4e7e172444d010c48a98c631991a2c3a8865992e974ec670c03785a9d1df"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from numbapro import cuda, vectorize\n",
      "import numbapro.cudalib.cufft as cufft "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%precision 4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "u'%.4f'"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Replicating examples from [Accelerate R Applications with CUDA ](http://devblogs.nvidia.com/parallelforall/accelerate-r-applications-cuda/)\n",
      "----"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### FFT example"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num = 4\n",
      "v = np.random.normal(0, 1, (num, 2))\n",
      "z = v[:,0] + 1j*v[:,1]\n",
      "print \"{:<20}\".format('Original'), z\n",
      "\n",
      "x_gpu = np.zeros(num, dtype='complex')\n",
      "cufft.fft(z, x_gpu)\n",
      "print \"{:<20}\".format('CUDA FFT'), x_gpu\n",
      "\n",
      "x_cpu = np.fft.fft(z)\n",
      "print \"{:<20}\".format('CPU  FFT'), x_cpu\n",
      "\n",
      "# NVidia IFFT returns unnormalzied results\n",
      "cufft.ifft(x_gpu, z) \n",
      "print \"{:<20}\".format('CUDA IFFT'), z/num\n",
      "\n",
      "x_cpu = np.fft.ifft(x_cpu)\n",
      "print \"{:<20}\".format('CPU  IFFT'), x_cpu"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Original             [-0.2414+1.2555j -0.0947-2.2246j  0.5452-1.7055j  0.9129+0.8522j]\n",
        "CUDA FFT            "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [ 1.1220-1.8225j -3.8633+3.9687j -0.5144+0.9224j  2.2902+1.9534j]\n",
        "CPU  FFT             [ 1.1220-1.8225j -3.8633+3.9687j -0.5144+0.9224j  2.2902+1.9534j]\n",
        "CUDA IFFT            [-0.2414+1.2555j -0.0947-2.2246j  0.5452-1.7055j  0.9129+0.8522j]\n",
        "CPU  IFFT            [-0.2414+1.2555j -0.0947-2.2246j  0.5452-1.7055j  0.9129+0.8522j]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Vector addition example"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Using CUDA Python to explicitly compile to PTX"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@cuda.jit('void(float64[:,], float64[:], float64[:], int64)')\n",
      "def gvectorAdd(A, B, C, n):\n",
      "    i = cuda.grid(1)\n",
      "    if i < n:\n",
      "        C[i] = A[i] + B[i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = 50\n",
      "A = np.arange(n, dtype=np.float64)\n",
      "B = np.arange(n, dtype=np.float64)\n",
      "C = np.empty_like(A)\n",
      "\n",
      "grid_dim = cuda.get_current_device().WARP_SIZE\n",
      "block_dim = (n + grid_dim - 1)/grid_dim\n",
      "\n",
      "print grid_dim\n",
      "print block_dim\n",
      "\n",
      "gvectorAdd[grid_dim, block_dim](A, B, C, n)\n",
      "C"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "32\n",
        "2\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "array([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,\n",
        "        22.,  24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,\n",
        "        44.,  46.,  48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,\n",
        "        66.,  68.,  70.,  72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,\n",
        "        88.,  90.,  92.,  94.,  96.,  98.])"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Using vectorize utility"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@vectorize('float64(float64, float64)', target='gpu')\n",
      "def gvectorAdd2(A, B):\n",
      "    return A + B"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gvectorAdd2(A, B)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "array([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,\n",
        "        22.,  24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,\n",
        "        44.,  46.,  48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,\n",
        "        66.,  68.,  70.,  72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,\n",
        "        88.,  90.,  92.,  94.,  96.,  98.])"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    }
   ],
   "metadata": {}
  }
 ]
}